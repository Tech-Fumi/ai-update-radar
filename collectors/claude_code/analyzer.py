#!/usr/bin/env python3
"""
Claude Code æ›´æ–°åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

æ©Ÿèƒ½:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã®åé›†ãƒ»åˆ†æ
- ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã® AI è§£æ
- é–‹ç™ºè¦–ç‚¹ã§ã®æ”¹å–„ææ¡ˆç”Ÿæˆ
- çµŒå–¶è¦–ç‚¹ã§ã®ä¼ç”»ææ¡ˆç”Ÿæˆ

ä½¿ç”¨ä¾‹:
  python analyzer.py --release-notes "æ–°æ©Ÿèƒ½: parallel tool calls"
  python analyzer.py --analyze-all
"""

import argparse
import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import requests
except ImportError:
    print("âŒ requests ãŒå¿…è¦ã§ã™: pip install requests")
    sys.exit(1)

# dotenv ã§ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv

    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã® .env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆANTHROPIC_API_KEY ãŒã‚ã‚‹ï¼‰
    ENV_FILE = Path.home() / ".env"
    if ENV_FILE.exists():
        load_dotenv(ENV_FILE)
except ImportError:
    pass  # dotenv ãŒãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç›´æ¥èª­ã‚€


# =============================================================================
# è¨­å®š
# =============================================================================

SCRIPT_DIR = Path(__file__).parent
PROJECTS_CONFIG = SCRIPT_DIR / "config" / "projects.json"
ANALYSIS_OUTPUT_DIR = SCRIPT_DIR / "analysis"
RELEASES_JSON = SCRIPT_DIR.parent.parent / "frontend" / "public" / "data" / "releases.json"

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆä¸€è¦§ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
DEFAULT_PROJECTS = [
    "/home/fumi/ScrimAutomationEngine",
    "/home/fumi/StreamFlowEngine",
    "/home/fumi/infra-automation",
    "/home/fumi/ai-company-os",
]

# Anthropic APIï¼ˆåˆ†æç”¨ï¼‰
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")


# =============================================================================
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šåé›†
# =============================================================================


def collect_project_info(project_root: str) -> dict:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¨­å®šæƒ…å ±ã‚’åé›†"""
    project_path = Path(project_root)

    if not project_path.exists():
        return {"error": f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {project_root}"}

    info = {
        "name": project_path.name,
        "path": str(project_path),
        "collected_at": datetime.now().isoformat(),
        "claude_md": None,
        "mcp_config": None,
        "package_json": None,
        "pyproject": None,
        "current_features": [],
        "pain_points": [],
        "business_context": None,
    }

    # CLAUDE.md ã‚’èª­ã¿å–ã‚Š
    claude_md_path = project_path / "CLAUDE.md"
    if claude_md_path.exists():
        content = claude_md_path.read_text(encoding="utf-8")
        info["claude_md"] = {
            "exists": True,
            "size": len(content),
            "content_preview": content[:2000],
            "phases": extract_phases(content),
            "todos": extract_todos(content),
        }
        # ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        info["business_context"] = extract_business_context(content)
        # èª²é¡Œãƒ»Pain Points ã‚’æŠ½å‡º
        info["pain_points"] = extract_pain_points(content)

    # .mcp.json ã‚’èª­ã¿å–ã‚Š
    mcp_config_path = project_path / ".mcp.json"
    if mcp_config_path.exists():
        try:
            mcp_data = json.loads(mcp_config_path.read_text())
            info["mcp_config"] = {
                "exists": True,
                "servers": list(mcp_data.get("mcpServers", {}).keys()),
            }
            info["current_features"].append("MCP ã‚µãƒ¼ãƒãƒ¼é€£æº")
        except json.JSONDecodeError:
            info["mcp_config"] = {"exists": True, "error": "ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"}

    # package.json ã‚’èª­ã¿å–ã‚Šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼‰
    package_json_path = project_path / "frontend" / "package.json"
    if not package_json_path.exists():
        package_json_path = project_path / "package.json"
    if package_json_path.exists():
        try:
            pkg_data = json.loads(package_json_path.read_text())
            info["package_json"] = {
                "exists": True,
                "name": pkg_data.get("name"),
                "dependencies": list(pkg_data.get("dependencies", {}).keys())[:20],
            }
        except json.JSONDecodeError:
            pass

    # pyproject.toml ã‚’èª­ã¿å–ã‚Š
    pyproject_path = project_path / "pyproject.toml"
    if pyproject_path.exists():
        info["pyproject"] = {"exists": True}
        info["current_features"].append("Python ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰")

    # Claude Code é–¢é€£ã®ä½¿ç”¨çŠ¶æ³ã‚’æ¨æ¸¬
    info["current_features"].extend(detect_claude_features(project_path))

    return info


def extract_phases(content: str) -> list:
    """CLAUDE.md ã‹ã‚‰ãƒ•ã‚§ãƒ¼ã‚ºæƒ…å ±ã‚’æŠ½å‡º"""
    phases = []
    phase_pattern = r"(?:Phase|ãƒ•ã‚§ãƒ¼ã‚º)\s*(\d+)[:\s]*(.+?)(?:\n|$)"
    for match in re.finditer(phase_pattern, content, re.IGNORECASE):
        phases.append(
            {
                "number": int(match.group(1)),
                "title": match.group(2).strip(),
            }
        )
    return phases


def extract_todos(content: str) -> dict:
    """CLAUDE.md ã‹ã‚‰ TODO çŠ¶æ³ã‚’æŠ½å‡º"""
    completed = len(re.findall(r"- \[x\]", content, re.IGNORECASE))
    pending = len(re.findall(r"- \[ \]", content))
    return {
        "completed": completed,
        "pending": pending,
        "total": completed + pending,
    }


def extract_business_context(content: str) -> Optional[dict]:
    """CLAUDE.md ã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    context = {}

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã‚’æ¢ã™
    overview_match = re.search(
        r"##?\s*(?:ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦|æ¦‚è¦|Overview)\s*\n([\s\S]*?)(?=\n##|\Z)", content
    )
    if overview_match:
        context["overview"] = overview_match.group(1).strip()[:500]

    # ç›®çš„ãƒ»ã‚´ãƒ¼ãƒ«ã‚’æ¢ã™
    goal_match = re.search(
        r"##?\s*(?:ç›®çš„|ã‚´ãƒ¼ãƒ«|ç›®æ¨™|Goal|Purpose)\s*\n([\s\S]*?)(?=\n##|\Z)", content
    )
    if goal_match:
        context["goal"] = goal_match.group(1).strip()[:500]

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¢ã™
    user_match = re.search(
        r"(?:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ|ãƒ¦ãƒ¼ã‚¶ãƒ¼|å¯¾è±¡|Target)\s*[:ï¼š]\s*(.+)", content
    )
    if user_match:
        context["target_user"] = user_match.group(1).strip()

    return context if context else None


def extract_pain_points(content: str) -> list:
    """CLAUDE.md ã‹ã‚‰èª²é¡Œãƒ»Pain Points ã‚’æŠ½å‡º"""
    pain_points = []

    # èª²é¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
    issue_match = re.search(
        r"##?\s*(?:èª²é¡Œ|å•é¡Œ|Issues?|Problems?|Pain Points?)\s*\n([\s\S]*?)(?=\n##|\Z)",
        content,
    )
    if issue_match:
        issues_text = issue_match.group(1)
        # ãƒªã‚¹ãƒˆé …ç›®ã‚’æŠ½å‡º
        for line in issues_text.split("\n"):
            if line.strip().startswith(("-", "*", "ãƒ»")):
                pain_points.append(line.strip().lstrip("-*ãƒ» "))

    # TODO ã®æœªå®Œäº†é …ç›®ã‚‚èª²é¡Œã¨ã—ã¦æ‰±ã†
    for match in re.finditer(r"- \[ \]\s*(.+)", content):
        if len(pain_points) < 10:  # æœ€å¤§10ä»¶
            pain_points.append(f"æœªå®Œäº†: {match.group(1)}")

    return pain_points[:10]


def detect_claude_features(project_path: Path) -> list:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ä¸­ã® Claude Code æ©Ÿèƒ½ã‚’æ¤œå‡º"""
    features = []

    # .claude ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    claude_dir = project_path / ".claude"
    if claude_dir.exists():
        features.append("Claude Code è¨­å®š")

        # hooks ã®å­˜åœ¨ç¢ºèª
        hooks_dir = claude_dir / "hooks"
        if hooks_dir.exists() and list(hooks_dir.glob("*.sh")):
            features.append("Claude Code Hooks")

        # commands ã®å­˜åœ¨ç¢ºèª
        commands_dir = claude_dir / "commands"
        if commands_dir.exists() and list(commands_dir.glob("*.md")):
            features.append("ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰")

    # session-manager ã®ä½¿ç”¨ç¢ºèª
    sessions_dir = project_path / ".claude" / "sessions"
    if sessions_dir.exists():
        features.append("ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†")

    return features


def collect_all_projects(project_roots: list = None) -> dict:
    """å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æƒ…å ±ã‚’åé›†"""
    if project_roots is None:
        # projects.json ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
        if PROJECTS_CONFIG.exists():
            config = json.loads(PROJECTS_CONFIG.read_text())
            project_roots = config.get("projects", DEFAULT_PROJECTS)
        else:
            project_roots = DEFAULT_PROJECTS

    results = {
        "collected_at": datetime.now().isoformat(),
        "projects": {},
    }

    for root in project_roots:
        print(f"ğŸ“‚ {Path(root).name} ã‚’åé›†ä¸­...")
        info = collect_project_info(root)
        results["projects"][info.get("name", root)] = info

    return results


# =============================================================================
# ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆåˆ†æ
# =============================================================================


def get_release_details(version: str) -> Optional[dict]:
    """releases.json ã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
    if not RELEASES_JSON.exists():
        return None

    try:
        data = json.loads(RELEASES_JSON.read_text())
        for release in data.get("releases", []):
            if release.get("version") == version:
                return release
    except Exception:
        pass
    return None


def enrich_release_notes(release_notes: str, version: str = None) -> str:
    """releases.json ã®è©³ç´°æƒ…å ±ã§ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’è£œå¼·"""
    if not version:
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’æŠ½å‡º
        match = re.search(r'v?\d+\.\d+\.\d+', release_notes)
        if match:
            version = match.group()
            if not version.startswith('v'):
                version = 'v' + version

    if not version:
        return release_notes

    details = get_release_details(version)
    if not details:
        return release_notes

    # è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
    enriched = [release_notes, "\n\n## è©³ç´°è§£èª¬ï¼ˆæ—¥æœ¬èªï¼‰"]

    # highlights_ja ã‚’è¿½åŠ 
    if details.get("highlights_ja"):
        enriched.append("\n### ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
        for h in details["highlights_ja"]:
            enriched.append(f"- {h}")

    # meanings ã‚’è¿½åŠ 
    if details.get("meanings"):
        enriched.append("\n### å„æ©Ÿèƒ½ã®æ„å‘³")
        for m in details["meanings"]:
            enriched.append(f"- **{m['title']}**: {m['meaning']}")

    return "\n".join(enriched)


def analyze_release_notes(release_notes: str, projects_info: dict, version: str = None) -> dict:
    """ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’åˆ†æã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å½±éŸ¿ã‚’è©•ä¾¡"""

    # releases.json ã®è©³ç´°æƒ…å ±ã§è£œå¼·
    enriched_notes = enrich_release_notes(release_notes, version)

    if not ANTHROPIC_API_KEY:
        return analyze_release_notes_simple(enriched_notes, projects_info)

    # AI ã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†æ
    return analyze_release_notes_ai(enriched_notes, projects_info)


def analyze_release_notes_simple(release_notes: str, projects_info: dict) -> dict:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®åˆ†æ"""
    analysis = {
        "analyzed_at": datetime.now().isoformat(),
        "method": "keyword_matching",
        "features_detected": [],
        "dev_improvements": [],
        "business_opportunities": [],
    }

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    keywords = {
        "performance": [
            "é€Ÿåº¦å‘ä¸Š",
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„",
            "é«˜é€ŸåŒ–",
            "faster",
            "performance",
        ],
        "parallel": ["ä¸¦åˆ—", "parallel", "concurrent", "åŒæ™‚å®Ÿè¡Œ"],
        "mcp": ["MCP", "Model Context Protocol", "ã‚µãƒ¼ãƒãƒ¼"],
        "hooks": ["hooks", "ãƒ•ãƒƒã‚¯", "ãƒˆãƒªã‚¬ãƒ¼"],
        "cost": ["ã‚³ã‚¹ãƒˆ", "ãƒˆãƒ¼ã‚¯ãƒ³", "åŠ¹ç‡", "cost", "token"],
        "api": ["API", "ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ", "çµ±åˆ"],
        "automation": ["è‡ªå‹•åŒ–", "automation", "auto"],
    }

    notes_lower = release_notes.lower()

    for category, words in keywords.items():
        for word in words:
            if word.lower() in notes_lower:
                analysis["features_detected"].append(
                    {
                        "category": category,
                        "keyword": word,
                    }
                )
                break

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã®ææ¡ˆç”Ÿæˆ
    detected_categories = [f["category"] for f in analysis["features_detected"]]

    for project_name, project_info in projects_info.get("projects", {}).items():
        if "error" in project_info:
            continue

        business_ctx = project_info.get("business_context", {})
        current_features = project_info.get("current_features", [])

        # é–‹ç™ºæ”¹å–„ææ¡ˆ
        if "parallel" in detected_categories:
            if "MCP ã‚µãƒ¼ãƒãƒ¼é€£æº" in current_features:
                analysis["dev_improvements"].append(
                    {
                        "project": project_name,
                        "suggestion": "ä¸¦åˆ—ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã§ MCP å‡¦ç†ã‚’é«˜é€ŸåŒ–",
                        "priority": "HIGH",
                        "estimated_impact": "å‡¦ç†æ™‚é–“ 30-50% å‰Šæ¸›è¦‹è¾¼ã¿",
                    }
                )

        if "performance" in detected_categories:
            analysis["dev_improvements"].append(
                {
                    "project": project_name,
                    "suggestion": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„æ©Ÿèƒ½ã®é©ç”¨æ¤œè¨",
                    "priority": "MEDIUM",
                    "estimated_impact": "å¿œç­”é€Ÿåº¦æ”¹å–„",
                }
            )

        if "mcp" in detected_categories:
            if "MCP ã‚µãƒ¼ãƒãƒ¼é€£æº" in current_features:
                analysis["dev_improvements"].append(
                    {
                        "project": project_name,
                        "suggestion": "MCP ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®æ´»ç”¨",
                        "priority": "MEDIUM",
                        "estimated_impact": "API å‘¼ã³å‡ºã—å‰Šæ¸›",
                    }
                )

        # çµŒå–¶è¦–ç‚¹ã®ææ¡ˆï¼ˆã‚ˆã‚Šç©æ¥µçš„ã«ç”Ÿæˆï¼‰
        if "automation" in detected_categories:
            business_ctx.get("overview", "") if business_ctx else ""
            analysis["business_opportunities"].append(
                {
                    "title": f"{project_name}: è‡ªå‹•åŒ–æ©Ÿèƒ½å¼·åŒ–",
                    "description": "æ–°ã—ã„è‡ªå‹•åŒ–æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ã‚µãƒ¼ãƒ“ã‚¹ä¾¡å€¤ã‚’å‘ä¸Š",
                    "affected_projects": [project_name],
                    "potential_value": "é‹ç”¨ã‚³ã‚¹ãƒˆå‰Šæ¸›ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å·®åˆ¥åŒ–",
                    "action_required": "è‡ªå‹•åŒ–å¯èƒ½ãªæ‰‹å‹•ãƒ—ãƒ­ã‚»ã‚¹ã®æ´—ã„å‡ºã—",
                }
            )

        if "parallel" in detected_categories:
            analysis["business_opportunities"].append(
                {
                    "title": f"{project_name}: å‡¦ç†é€Ÿåº¦å‘ä¸Šã«ã‚ˆã‚‹UXæ”¹å–„",
                    "description": "ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Š",
                    "affected_projects": [project_name],
                    "potential_value": "ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦å‘ä¸Šãƒ»é›¢è„±ç‡ä½ä¸‹",
                    "action_required": "ä¸¦åˆ—åŒ–å¯èƒ½ãªå‡¦ç†ã®ç‰¹å®šã¨å®Ÿè£…",
                }
            )

        if "api" in detected_categories and business_ctx:
            analysis["business_opportunities"].append(
                {
                    "title": f"{project_name}: API é€£æºå¼·åŒ–",
                    "description": "æ–°ã—ã„ API æ©Ÿèƒ½ã§å¤–éƒ¨é€£æºã‚’æ‹¡å¤§",
                    "affected_projects": [project_name],
                    "potential_value": "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—æ©Ÿä¼šãƒ»æ©Ÿèƒ½æ‹¡å¼µ",
                    "action_required": "é€£æºå¯èƒ½ãªå¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã®èª¿æŸ»",
                }
            )

    # é‡è¤‡æ’é™¤
    seen_titles = set()
    unique_opportunities = []
    for opp in analysis["business_opportunities"]:
        title = opp.get("title", "")
        if title not in seen_titles:
            seen_titles.add(title)
            unique_opportunities.append(opp)
    analysis["business_opportunities"] = unique_opportunities

    return analysis


def analyze_release_notes_ai(release_notes: str, projects_info: dict) -> dict:
    """AI ã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†æ"""

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«æ•´å½¢
    projects_summary = []
    for name, info in projects_info.get("projects", {}).items():
        if "error" in info:
            continue
        claude_md = info.get("claude_md") or {}
        projects_summary.append(
            {
                "name": name,
                "business_context": info.get("business_context"),
                "current_features": info.get("current_features", []),
                "pain_points": info.get("pain_points", [])[:5],
                "todos": claude_md.get("todos"),
            }
        )

    prompt = f"""ã‚ãªãŸã¯ "Release Notes Analyzer" ã§ã™ã€‚
å…¥åŠ›ã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã‚‹ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆï¼ˆå¤‰æ›´ç‚¹ã®æ–‡ç« ï¼‰ã‚’èª­ã¿ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå–ã‚‹ã¹ãå¯¾å¿œã‚’ã€èª¤è§£ãªãæœ€å°ä½œæ¥­ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚

# æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ï¼ˆéå‰°è§£é‡ˆé˜²æ­¢ï¼‰
1) ã¾ãšã€Œå¸°å±åˆ¤å®šï¼ˆèª°/ä½•ã®å•é¡Œã‹ï¼‰ã€ã‚’å¿…ãšè¡Œã†ã€‚å¸°å±åˆ¤å®šãªã—ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡ºã—ã¦ã¯ã„ã‘ãªã„ã€‚
2) "Upstreamï¼ˆå¤–éƒ¨ãƒ„ãƒ¼ãƒ«/ä¾å­˜/OS/ã‚µãƒ¼ãƒ“ã‚¹å´ã®ä¿®æ­£ï¼‰" ã¨
   "Downstreamï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚³ãƒ¼ãƒ‰/è¨­å®šå¤‰æ›´ãŒå¿…è¦ï¼‰" ã‚’å¿…ãšåˆ†é¡ã™ã‚‹ã€‚
3) Downstream ã ã¨ç¢ºå®šã§ããªã„é™ã‚Šã€ã€Œå…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é©ç”¨ã€ã€Œå…¨ãƒªãƒã«PRã€ã‚’ææ¡ˆã—ã¦ã¯ã„ã‘ãªã„ã€‚
4) ä¸ç¢ºå®Ÿãªå ´åˆã¯ã€"è¦ç¢ºèª" ã¨ã—ã¦è³ªå•ã§ã¯ãªãã€Œç¢ºèªã™ã¹ãè¦³ç‚¹ã€ã‚’åˆ—æŒ™ã—ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ä¿ç•™/æœ€å°ã«ã™ã‚‹ã€‚

# ç”¨èª
- Upstream: Claude Codeæœ¬ä½“ / CLIãƒ„ãƒ¼ãƒ« / OS / ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª / SaaS / ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  ãªã© "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªãƒå¤–" ã®ä¿®æ­£
- Downstream: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã®ã‚³ãƒ¼ãƒ‰/è¨­å®š/é‹ç”¨æ‰‹é †å¤‰æ›´ãŒå¿…è¦ãªä¿®æ­£

# åˆ†é¡ãƒ«ãƒ¼ãƒ«ï¼ˆå¼·åˆ¶ï¼‰
æ¬¡ã®åˆ¤å®šãƒ•ãƒ­ãƒ¼ã§åˆ†é¡ã›ã‚ˆã€‚

Step 1: ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã« "tool/product name" ãŒå«ã¾ã‚Œã‚‹ã‹ï¼Ÿ
- å«ã¾ã‚Œã‚‹ â†’ Upstream ã®å¯èƒ½æ€§ãŒé«˜ã„
- å«ã¾ã‚Œãªã„ â†’ dependency ã‹ user's project ã®å¯èƒ½æ€§

Step 2: "fixed security vulnerability" ã®å¯¾è±¡ã¯ã©ã“ã‹ï¼Ÿ
- æ¨©é™åˆ¤å®š/CLIæŒ™å‹•/å®Ÿè¡ŒåŸºç›¤ã®ä¿®æ­£ â†’ Upstream
- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè„†å¼±æ€§ï¼ˆCVE/ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰ â†’ Upstream(ä¾å­˜æ›´æ–°) ã ãŒé©ç”¨ã¯å„ãƒªãƒï¼ˆ=Mixedã«ãªã‚Šã†ã‚‹ï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ¼ãƒ‰ã®æ¬ é™¥ã‚’ç¤ºå”† â†’ Downstream

Step 3: "å…¨ãƒªãƒé©ç”¨" ã‚’è¨±å¯ã™ã‚‹æ¡ä»¶
- ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆãŒç‰¹å®šã®ä¾å­˜ï¼ˆä¾‹: lodash, openssl ç­‰ï¼‰æ›´æ–°ã‚’è¦æ±‚ã—ã€è¤‡æ•°ãƒªãƒãŒãã®ä¾å­˜ã‚’æŒã¤å¯èƒ½æ€§ãŒé«˜ã„
- ã¾ãŸã¯ã€å…±é€šãƒ†ãƒ³ãƒ—ãƒ¬/å…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé‹ç”¨ã—ã¦ã„ã‚‹å‰æãŒæ˜ç¢º
â†’ ãã‚Œä»¥å¤–ã¯å…¨ãƒªãƒé©ç”¨ç¦æ­¢ã€‚å¯¾è±¡ãƒªãƒã®åŒå®šãŒå¿…è¦ã€‚

# å…¥åŠ›

## ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆ
{release_notes}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
{json.dumps(projects_summary, ensure_ascii=False, indent=2)}

# å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã® Markdown ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¿…ãšã“ã®é †ã§å‡ºåŠ›ã—ã€æœ€å¾Œã« JSON ã‚’å‡ºåŠ›ã™ã‚‹ã€‚

## 0. Summary
- 1ã€œ2è¡Œã§è¦ç´„ï¼ˆä½•ãŒå¤‰ã‚ã£ãŸã‹ / ä½•ã‚’ã™ã¹ãã‹ï¼‰

## 1. Attributionï¼ˆå¸°å±åˆ¤å®šï¼‰
æ¬¡ã®4é …ç›®ã‚’åŸ‹ã‚ã‚‹ï¼ˆä¸æ˜ãªã‚‰ "Unknown"ï¼‰
- Affected Component: {{ä¾‹: Claude Code / OS / dependency:xx / user's project / CI runner}}
- Issue Type: {{security / bugfix / performance / behavior change / deprecation / new feature}}
- Patch Location: {{upgrade tool / upgrade dependency / change repo code / change config / change docs/runbook}}
- Classification: {{Upstream / Downstream / Mixed / Unknown}}

### Evidence
- ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®è©²å½“æ–‡ã‹ã‚‰ã€åˆ¤æ–­ã®æ ¹æ‹ ã‚’çŸ­ãç®‡æ¡æ›¸ãï¼ˆå¼•ç”¨ã¯25èªä»¥å†…ã®æŠœç²‹ã«ã™ã‚‹ï¼‰

## 2. Impact & Scopeï¼ˆå½±éŸ¿ã¨ç¯„å›²ï¼‰
- Scope Target: {{single machine / all dev machines / CI runners / specific repos / all repos}}
- Risk Level: {{Low/Med/High}}ï¼ˆç†ç”±ã‚‚1è¡Œï¼‰
- Who is affected: {{ä¾‹: Claude Code ã‚’å®Ÿè¡Œã™ã‚‹ç’°å¢ƒã€ç‰¹å®šã®OSã€ç‰¹å®šã®è¨­å®šåˆ©ç”¨è€…}}

## 3. Required Actionsï¼ˆå¿…é ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
ãƒ«ãƒ¼ãƒ«:
- Upstream ã®å ´åˆ: "ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ/ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ/ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®š" ãŒä¸­å¿ƒã€‚ãƒªãƒã¸ã®PRã¯åŸå‰‡ç¦æ­¢ã€‚
- Downstream ã®å ´åˆ: å¯¾è±¡ãƒªãƒã¨å¤‰æ›´ç‚¹ã‚’å…·ä½“åŒ–ã€‚å¯¾è±¡ä¸æ˜ãªã‚‰ "è¦ç¢ºèª" ã¨ã—ã€å…¨ãƒªãƒé©ç”¨ã—ãªã„ã€‚

## 4. Optional Actionsï¼ˆä»»æ„/æ”¹å–„ï¼‰
- "å¿…é ˆ" ã§ã¯ãªã„æ”¹å–„ã‚„ç›£è¦–ï¼ˆä¾‹: ç›£æŸ»ãƒ­ã‚°å¼·åŒ–ã€æ¤œçŸ¥è¿½åŠ ï¼‰
- Downstream æ–­å®šãŒãªã„å ´åˆã¯ "è¦ç¢ºèª" ã‚’ä»˜ã‘ã‚‹

## 5. Anti-Patternsï¼ˆã‚„ã£ã¦ã¯ã„ã‘ãªã„èª¤è§£ï¼‰
- ä»Šå›ã®å†…å®¹ã§ "èª¤ã£ã¦ã‚„ã‚ŠãŒã¡ãªè¡Œå‹•" ã‚’1ã€œ3å€‹
  ä¾‹: ã€Œå…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ‘ãƒƒãƒã‚’å½“ã¦ã‚‹ã€ãªã©

## 6. Machine Output (JSON)

æœ€å¾Œã«ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã® JSON ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
**é‡è¦**: Upstream ã®ä¿®æ­£ï¼ˆClassification == Upstreamï¼‰ã®å ´åˆ:
- action_items ã® project ã¯ "Claude Code" ã‚„ "all dev environments" ã®ã‚ˆã†ã«ãƒ„ãƒ¼ãƒ«/ç’°å¢ƒã‚’æŒ‡å®š
- å€‹åˆ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ project ã«å…¥ã‚Œã¦ã¯ã„ã‘ãªã„
- category ã¯ "tooling" ã‚’ä½¿ç”¨

JSONå½¢å¼:
{{
  "attribution": {{
    "affected_component": "...",
    "issue_type": "...",
    "patch_location": "...",
    "classification": "Upstream/Downstream/Mixed/Unknown",
    "scope_target": "...",
    "risk_level": "Low/Med/High"
  }},
  "dev_improvements": [
    {{
      "project": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆUpstreamãªã‚‰ 'Claude Code' ç­‰ï¼‰",
      "suggestion": "å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ",
      "source_feature": "ã“ã®ææ¡ˆã®å…ƒã«ãªã£ãŸãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®æ©Ÿèƒ½ï¼ˆæ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰",
      "what_it_is": "å®Ÿéš›ã«ä½•ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã‹ã€‚Before/Afterã§èª¬æ˜ï¼ˆä¾‹: ä»¥å‰ã¯â—‹â—‹ã ã£ãŸ â†’ ä»Šã¯â–³â–³ã§ãã‚‹ï¼‰ã€‚å°‚é–€ç”¨èªãªã—ã§å…·ä½“çš„ã«",
      "merit": "ã“ã‚Œã‚’ä½¿ã†ã¨ä½•ãŒå¬‰ã—ã„ã‹ï¼ˆå…·ä½“çš„ãªå ´é¢ã§ï¼‰",
      "demerit": "ã“ã‚Œã‚’ä½¿ã†ã¨ä½•ã‚’å¤±ã†ã‹ã€ã¾ãŸã¯æ³¨æ„ç‚¹",
      "target_area": "å¯¾è±¡ç®‡æ‰€",
      "expected_impact": "æœŸå¾…åŠ¹æœ",
      "priority": "HIGH/MEDIUM/LOW",
      "effort": "å°å…¥å·¥æ•°ã®è¦‹ç©ã‚‚ã‚Š"
    }}
  ],
  "business_opportunities": [
    {{
      "title": "æ©Ÿä¼šã®ã‚¿ã‚¤ãƒˆãƒ«",
      "source_feature": "ã“ã®æ©Ÿä¼šã®å…ƒã«ãªã£ãŸãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®æ©Ÿèƒ½ï¼ˆæ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰",
      "what_it_is": "å®Ÿéš›ã«ä½•ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã‹ã€‚Before/Afterã§èª¬æ˜ï¼ˆä¾‹: ä»¥å‰ã¯â—‹â—‹ã ã£ãŸ â†’ ä»Šã¯â–³â–³ã§ãã‚‹ï¼‰ã€‚å°‚é–€ç”¨èªãªã—ã§å…·ä½“çš„ã«",
      "merit": "ã“ã‚Œã‚’æ´»ç”¨ã™ã‚‹ã¨ä½•ãŒå¬‰ã—ã„ã‹ï¼ˆå…·ä½“çš„ãªå ´é¢ã§ï¼‰",
      "demerit": "ãƒªã‚¹ã‚¯ã‚„æ³¨æ„ç‚¹",
      "description": "è©³ç´°èª¬æ˜",
      "affected_projects": ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå"],
      "potential_value": "æœŸå¾…ä¾¡å€¤",
      "action_required": "å¿…è¦ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
    }}
  ],
  "action_items": [
    {{
      "task": "ã‚¿ã‚¹ã‚¯å†…å®¹ï¼ˆæ›´æ–°ç³»ãªã‚‰å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å«ã‚ã‚‹ã€‚ä¾‹: 'Claude Code v2.1.7 ã«æ›´æ–°'ï¼‰",
      "source_feature": "å…ƒã«ãªã£ãŸãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®æ©Ÿèƒ½ï¼ˆæ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰",
      "priority": 1,
      "project": "å¯¾è±¡ï¼ˆUpstreamãªã‚‰ 'Claude Code' / 'all dev environments' ç­‰ï¼‰",
      "category": "dev/business/tooling"
    }}
  ],
  "anti_patterns": ["ã‚„ã£ã¦ã¯ã„ã‘ãªã„èª¤è§£1", "ã‚„ã£ã¦ã¯ã„ã‘ãªã„èª¤è§£2"]
}}
"""

    try:
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            },
            json={
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 4096,
                "messages": [{"role": "user", "content": prompt}],
            },
            timeout=60,
        )
        response.raise_for_status()

        result = response.json()
        content = result["content"][0]["text"]

        # JSON éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r"\{[\s\S]*\}", content)
        if json_match:
            analysis = json.loads(json_match.group())
            analysis["analyzed_at"] = datetime.now().isoformat()
            analysis["method"] = "ai_analysis"
            return analysis

    except Exception as e:
        print(f"âš ï¸ AI åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return analyze_release_notes_simple(release_notes, projects_info)


# =============================================================================
# ææ¡ˆç”Ÿæˆãƒ»å‡ºåŠ›
# =============================================================================


def generate_report(analysis: dict, projects_info: dict, version: str = None) -> str:
    """åˆ†æçµæœã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

    report = []
    report.append("# Claude Code æ›´æ–°å½±éŸ¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    report.append(f"\nç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    report.append(f"åˆ†ææ‰‹æ³•: {analysis.get('method', 'unknown')}")

    # è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯
    if version:
        report.append(f"\nğŸ“– **è©³ç´°ãƒšãƒ¼ã‚¸**: http://localhost:3102/releases/{version}")

    # é–‹ç™ºè¦–ç‚¹
    report.append("\n## ğŸ”§ é–‹ç™ºè¦–ç‚¹ã§ã®æ”¹å–„ææ¡ˆ\n")

    dev_improvements = analysis.get("dev_improvements", [])
    if dev_improvements:
        for imp in dev_improvements:
            priority_emoji = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}.get(
                imp.get("priority", "MEDIUM"), "âšª"
            )
            report.append(f"### {priority_emoji} {imp.get('project', 'Unknown')}")
            if imp.get("source_feature"):
                report.append(f"- **æ ¹æ‹ **: `{imp['source_feature']}`")
            report.append(f"- **ææ¡ˆ**: {imp.get('suggestion', '')}")
            if imp.get("target_area"):
                report.append(f"- **å¯¾è±¡**: {imp['target_area']}")
            if imp.get("expected_impact"):
                report.append(f"- **æœŸå¾…åŠ¹æœ**: {imp['expected_impact']}")
            if imp.get("effort"):
                report.append(f"- **å·¥æ•°**: {imp['effort']}")
            report.append("")
    else:
        report.append("_é–‹ç™ºæ”¹å–„ææ¡ˆãªã—_\n")

    # çµŒå–¶è¦–ç‚¹
    report.append("\n## ğŸ’¼ çµŒå–¶è¦–ç‚¹ã§ã®æ©Ÿä¼š\n")

    opportunities = analysis.get("business_opportunities", [])
    if opportunities:
        for opp in opportunities:
            report.append(
                f"### ğŸ’¡ {opp.get('title', opp.get('opportunity', 'Unknown'))}"
            )
            if opp.get("source_feature"):
                report.append(f"- **æ ¹æ‹ **: `{opp['source_feature']}`")
            if opp.get("description"):
                report.append(f"{opp['description']}")
            if opp.get("affected_projects"):
                report.append(
                    f"- **é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {', '.join(opp['affected_projects'])}"
                )
            if opp.get("potential_value"):
                report.append(f"- **æœŸå¾…ä¾¡å€¤**: {opp['potential_value']}")
            if opp.get("action_required") or opp.get("action"):
                report.append(
                    f"- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: {opp.get('action_required') or opp.get('action')}"
                )
            report.append("")
    else:
        report.append("_ãƒ“ã‚¸ãƒã‚¹æ©Ÿä¼šãªã—_\n")

    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
    action_items = analysis.get("action_items", [])
    if action_items:
        report.append("\n## âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆå„ªå…ˆåº¦é †ï¼‰\n")
        for i, item in enumerate(
            sorted(action_items, key=lambda x: x.get("priority", 99)), 1
        ):
            category_emoji = "ğŸ”§" if item.get("category") == "dev" else "ğŸ’¼"
            report.append(
                f"{i}. {category_emoji} [{item.get('project', 'General')}] {item.get('task', '')}"
            )
        report.append("")

    return "\n".join(report)


def save_analysis(analysis: dict, report: str, release_tag: str = None):
    """åˆ†æçµæœã‚’ä¿å­˜"""
    ANALYSIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    tag_suffix = f"_{release_tag}" if release_tag else ""

    # JSON ä¿å­˜
    json_path = ANALYSIS_OUTPUT_DIR / f"analysis{tag_suffix}_{timestamp}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)

    # Markdown ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    md_path = ANALYSIS_OUTPUT_DIR / f"report{tag_suffix}_{timestamp}.md"
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(report)

    # releases.json ã«åˆ†æçµæœã‚’çµ±åˆ
    if release_tag and RELEASES_JSON.exists():
        try:
            releases_data = json.loads(RELEASES_JSON.read_text())
            for release in releases_data.get("releases", []):
                if release.get("version") == release_tag:
                    # åˆ†æçµæœã‚’è©²å½“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«è¿½åŠ 
                    release["analysis"] = {
                        "dev_improvements": analysis.get("dev_improvements", []),
                        "business_opportunities": analysis.get("business_opportunities", []),
                        "action_items": analysis.get("action_items", []),
                        "analyzed_at": analysis.get("analyzed_at"),
                        "method": analysis.get("method"),
                    }
                    break
            # æ›´æ–°ã‚’ä¿å­˜
            with open(RELEASES_JSON, "w", encoding="utf-8") as f:
                json.dump(releases_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“Š releases.json ã«åˆ†æçµæœã‚’çµ±åˆ: {release_tag}")
        except Exception as e:
            print(f"âš ï¸ releases.json æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    print(f"ğŸ“ åˆ†æçµæœã‚’ä¿å­˜: {json_path}")
    print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {md_path}")

    return json_path, md_path


# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================


def main():
    parser = argparse.ArgumentParser(description="Claude Code æ›´æ–°åˆ†æã‚¨ãƒ³ã‚¸ãƒ³")
    parser.add_argument(
        "--release-notes",
        "-r",
        help="åˆ†æã™ã‚‹ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰",
    )
    parser.add_argument(
        "--release-tag",
        "-t",
        help="ãƒªãƒªãƒ¼ã‚¹ã‚¿ã‚°ï¼ˆä¿å­˜æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰",
    )
    parser.add_argument(
        "--collect-only",
        action="store_true",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®åé›†ã®ã¿ï¼ˆåˆ†æã—ãªã„ï¼‰",
    )
    parser.add_argument(
        "--analyze-all",
        action="store_true",
        help="æœ€æ–°ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‹ã‚‰è‡ªå‹•åˆ†æ",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="çµæœã‚’ JSON ã§å‡ºåŠ›",
    )

    args = parser.parse_args()

    print("ğŸ”¬ Claude Code æ›´æ–°åˆ†æã‚¨ãƒ³ã‚¸ãƒ³")
    print("=" * 50)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±åé›†
    print("\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’åé›†ä¸­...")
    projects_info = collect_all_projects()

    if args.collect_only:
        if args.json:
            print(json.dumps(projects_info, ensure_ascii=False, indent=2))
        else:
            for name, info in projects_info["projects"].items():
                print(f"\nğŸ“‚ {name}")
                print(f"   æ©Ÿèƒ½: {', '.join(info.get('current_features', []))}")
                if info.get("business_context"):
                    print(
                        f"   æ¦‚è¦: {info['business_context'].get('overview', '')[:100]}..."
                    )
        return

    # ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆå–å¾—
    release_notes = None

    if args.release_notes:
        # ãƒ‘ã‚¹ã£ã½ã„æ–‡å­—åˆ—ã‹ã¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿èª­ã¿è¾¼ã¿
        notes_path = Path(args.release_notes)
        if (
            len(args.release_notes) < 256
            and not args.release_notes.startswith("#")
            and notes_path.exists()
        ):
            release_notes = notes_path.read_text()
        else:
            release_notes = args.release_notes
    elif args.analyze_all:
        # æœ€æ–°ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’æ¢ã™
        artifacts_dir = SCRIPT_DIR / "artifacts" / "claude_code"
        if artifacts_dir.exists():
            latest_dirs = sorted(artifacts_dir.iterdir(), reverse=True)
            if latest_dirs:
                for artifact_file in latest_dirs[0].glob("*.json"):
                    try:
                        data = json.loads(artifact_file.read_text())
                        if "change" in data and "details" in data["change"]:
                            details = data["change"]["details"]
                            if "body" in details:
                                release_notes = details["body"]
                                args.release_tag = details.get("tag", "unknown")
                                break
                    except:
                        pass

    if not release_notes:
        print("âš ï¸ ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä½¿ç”¨ä¾‹:")
        print('  python analyzer.py --release-notes "æ–°æ©Ÿèƒ½: parallel tool calls"')
        print("  python analyzer.py --analyze-all")
        return

    print("\nğŸ“ ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’åˆ†æä¸­...")
    print(f"   å†…å®¹: {release_notes[:100]}...")
    if args.release_tag:
        print(f"   ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {args.release_tag}")

    # åˆ†æå®Ÿè¡Œï¼ˆreleases.json ã®è©³ç´°æƒ…å ±ã‚‚æ´»ç”¨ï¼‰
    analysis = analyze_release_notes(release_notes, projects_info, version=args.release_tag)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = generate_report(analysis, projects_info, version=args.release_tag)

    if args.json:
        print(json.dumps(analysis, ensure_ascii=False, indent=2))
    else:
        print("\n" + report)

    # ä¿å­˜
    save_analysis(analysis, report, args.release_tag)

    print("\n" + "=" * 50)
    print("âœ… åˆ†æå®Œäº†")


if __name__ == "__main__":
    main()
