"""
AI Update Radar - çµ±åˆ CLI
å…¨ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’çµ±åˆã—ã¦å®Ÿè¡Œ
"""

import json
import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional

import typer
import yaml
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from collectors.github_collector import GitHubCollector
from collectors.models import Category, CollectionResult
from collectors.page_diff_collector import PageDiffCollector
from collectors.rss_collector import RSSCollector

app = typer.Typer(help="AI Update Radar - AI ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆç›£è¦–ãƒ„ãƒ¼ãƒ«")
console = Console()


def get_paths() -> tuple[Path, Path, Path, Path]:
    """ãƒ‘ã‚¹è¨­å®šã‚’å–å¾—"""
    base_dir = Path(__file__).parent.parent
    sources_dir = base_dir / "sources"
    cache_dir = base_dir / ".private" / "cache"
    keywords_path = sources_dir / "keywords.yaml"
    exports_dir = base_dir / "exports"
    return sources_dir, cache_dir, keywords_path, exports_dir


def format_results_table(results: list[CollectionResult], title: str) -> None:
    """çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º"""
    all_entries = []
    for result in results:
        all_entries.extend(result.entries)

    if not all_entries:
        console.print(f"[dim]{title}: æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªãªã—[/dim]")
        return

    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
    min_dt = datetime.min.replace(tzinfo=timezone.utc)
    all_entries.sort(key=lambda e: e.published_at or min_dt, reverse=True)

    table = Table(title=f"{title} ({len(all_entries)} ä»¶)")
    table.add_column("æ—¥ä»˜", style="dim", width=6)
    table.add_column("ã‚½ãƒ¼ã‚¹", width=20)
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", width=50)
    table.add_column("ã‚«ãƒ†ã‚´ãƒª", width=12)
    table.add_column("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", style="cyan", width=20)

    for entry in all_entries[:20]:  # æœ€å¤§20ä»¶
        date_str = entry.published_at.strftime("%m/%d") if entry.published_at else "-"
        cats = ", ".join(c.value for c in entry.categories[:2])
        kws = ", ".join(entry.keywords[:3])
        table.add_row(date_str, entry.source_name[:20], entry.title[:50], cats, kws)

    console.print(table)


def print_errors(results: list[CollectionResult]) -> None:
    """ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º"""
    for result in results:
        for err in result.errors:
            console.print(f"[red]Error ({result.source_name}): {err}[/red]")


@app.command()
def collect(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’åé›†"),
    rss: bool = typer.Option(True, help="RSS ã‚’åé›†"),
    github: bool = typer.Option(True, help="GitHub ãƒªãƒªãƒ¼ã‚¹ã‚’åé›†"),
    pages: bool = typer.Option(True, help="ãƒšãƒ¼ã‚¸å·®åˆ†ã‚’æ¤œå‡º"),
    export: bool = typer.Option(False, help="JSON ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"),
    output: Optional[str] = typer.Option(None, help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå…ˆãƒ•ã‚¡ã‚¤ãƒ«å"),
):
    """
    å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’åé›†

    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ RSSã€GitHubã€ãƒšãƒ¼ã‚¸å·®åˆ†ã‚’ã™ã¹ã¦åé›†
    """
    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)
    since = since - timedelta(days=days)

    all_results: list[CollectionResult] = []

    # RSS åé›†
    if rss:
        console.print("[bold]ğŸ“° RSS ãƒ•ã‚£ãƒ¼ãƒ‰åé›†ä¸­...[/bold]")
        rss_collector = RSSCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            keywords_path=keywords_path,
        )
        rss_results = rss_collector.collect_all(since=since)
        all_results.extend(rss_results)
        format_results_table(rss_results, "RSS ãƒ•ã‚£ãƒ¼ãƒ‰")
        print_errors(rss_results)
        console.print()

    # GitHub åé›†
    if github:
        console.print("[bold]ğŸ™ GitHub ãƒªãƒªãƒ¼ã‚¹åé›†ä¸­...[/bold]")
        github_collector = GitHubCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            token=os.environ.get("GITHUB_TOKEN"),
            keywords_path=keywords_path,
        )
        github_results = github_collector.collect_all(since=since)
        all_results.extend(github_results)
        format_results_table(github_results, "GitHub ãƒªãƒªãƒ¼ã‚¹")
        print_errors(github_results)
        console.print()

    # ãƒšãƒ¼ã‚¸å·®åˆ†
    if pages:
        console.print("[bold]ğŸ” ãƒšãƒ¼ã‚¸å·®åˆ†æ¤œå‡ºä¸­...[/bold]")
        page_collector = PageDiffCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            keywords_path=keywords_path,
        )
        page_results = page_collector.collect_all()
        all_results.extend(page_results)
        format_results_table(page_results, "ãƒšãƒ¼ã‚¸å·®åˆ†")
        print_errors(page_results)
        console.print()

    # ã‚µãƒãƒª
    total_entries = sum(len(r.entries) for r in all_results)
    total_errors = sum(len(r.errors) for r in all_results)

    summary = Panel(
        f"ğŸ“Š åé›†å®Œäº†\n"
        f"  â€¢ ã‚¨ãƒ³ãƒˆãƒª: {total_entries} ä»¶\n"
        f"  â€¢ ã‚¨ãƒ©ãƒ¼: {total_errors} ä»¶\n"
        f"  â€¢ æœŸé–“: éå» {days} æ—¥",
        title="ã‚µãƒãƒª",
        border_style="green" if total_errors == 0 else "yellow",
    )
    console.print(summary)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if export:
        exports_dir.mkdir(parents=True, exist_ok=True)
        if output:
            export_path = exports_dir / output
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_path = exports_dir / f"collection_{timestamp}.json"

        export_data = {
            "collected_at": datetime.now(timezone.utc).isoformat(),
            "days": days,
            "results": [r.to_dict() for r in all_results],
        }

        with open(export_path, "w") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        console.print(f"[green]âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {export_path}[/green]")


@app.command()
def summary(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’é›†è¨ˆ"),
    category: Optional[str] = typer.Option(None, help="ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿"),
):
    """
    åé›†çµæœã®ã‚µãƒãƒªã‚’è¡¨ç¤º

    ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ»ã‚½ãƒ¼ã‚¹åˆ¥ã®é›†è¨ˆ
    """
    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc) - timedelta(days=days)

    # å…¨ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼å®Ÿè¡Œ
    all_entries = []

    # RSS
    rss_collector = RSSCollector(
        sources_dir=sources_dir, cache_dir=cache_dir, keywords_path=keywords_path
    )
    for result in rss_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # GitHub
    github_collector = GitHubCollector(
        sources_dir=sources_dir,
        cache_dir=cache_dir,
        token=os.environ.get("GITHUB_TOKEN"),
        keywords_path=keywords_path,
    )
    for result in github_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿
    if category:
        try:
            cat_filter = Category(category)
            all_entries = [e for e in all_entries if cat_filter in e.categories]
        except ValueError:
            console.print(f"[red]ä¸æ­£ãªã‚«ãƒ†ã‚´ãƒª: {category}[/red]")
            console.print(f"æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒª: {[c.value for c in Category]}")
            return

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
    cat_counts = {}
    for entry in all_entries:
        for cat in entry.categories:
            cat_counts[cat.value] = cat_counts.get(cat.value, 0) + 1

    # ã‚½ãƒ¼ã‚¹åˆ¥é›†è¨ˆ
    source_counts = {}
    for entry in all_entries:
        source_counts[entry.source_name] = source_counts.get(entry.source_name, 0) + 1

    # è¡¨ç¤º
    console.print(Panel(f"éå» {days} æ—¥é–“ã®ã‚µãƒãƒª", style="bold"))

    if cat_counts:
        cat_table = Table(title="ã‚«ãƒ†ã‚´ãƒªåˆ¥")
        cat_table.add_column("ã‚«ãƒ†ã‚´ãƒª")
        cat_table.add_column("ä»¶æ•°", justify="right")
        for cat, count in sorted(cat_counts.items(), key=lambda x: -x[1]):
            cat_table.add_row(cat, str(count))
        console.print(cat_table)
    else:
        console.print("[dim]ã‚¨ãƒ³ãƒˆãƒªãªã—[/dim]")

    if source_counts:
        source_table = Table(title="ã‚½ãƒ¼ã‚¹åˆ¥")
        source_table.add_column("ã‚½ãƒ¼ã‚¹")
        source_table.add_column("ä»¶æ•°", justify="right")
        for source, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:
            source_table.add_row(source, str(count))
        console.print(source_table)


@app.command()
def sources():
    """ç›£è¦–å¯¾è±¡ã‚½ãƒ¼ã‚¹ã®ä¸€è¦§ã‚’è¡¨ç¤º"""
    sources_dir, _, _, _ = get_paths()

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    providers_path = sources_dir / "providers.yaml"
    if providers_path.exists():
        with open(providers_path) as f:
            providers = yaml.safe_load(f) or {}

        table = Table(title="ğŸ“° ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼")
        table.add_column("ID")
        table.add_column("åå‰")
        table.add_column("å„ªå…ˆåº¦")
        table.add_column("ã‚½ãƒ¼ã‚¹æ•°")

        for pid, pdata in providers.get("providers", {}).items():
            table.add_row(
                pid,
                pdata.get("name", ""),
                str(pdata.get("priority", "-")),
                str(len(pdata.get("sources", []))),
            )
        console.print(table)
        console.print()

    # ãƒªãƒã‚¸ãƒˆãƒª
    repos_path = sources_dir / "repositories.yaml"
    if repos_path.exists():
        with open(repos_path) as f:
            repos = yaml.safe_load(f) or {}

        table = Table(title="ğŸ™ GitHub ãƒªãƒã‚¸ãƒˆãƒª")
        table.add_column("ID")
        table.add_column("ãƒªãƒã‚¸ãƒˆãƒª")
        table.add_column("å„ªå…ˆåº¦")
        table.add_column("ç›£è¦–å¯¾è±¡")

        for rid, rdata in repos.get("repositories", {}).items():
            table.add_row(
                rid,
                rdata.get("repo", ""),
                str(rdata.get("priority", "-")),
                ", ".join(rdata.get("watch", [])),
            )
        console.print(table)


@app.command()
def init():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆæœŸåŒ–ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã«æ¨å¥¨ï¼‰"""
    _, cache_dir, _, _ = get_paths()

    cache_dir.mkdir(parents=True, exist_ok=True)

    # æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
    count = 0
    for f in cache_dir.glob("*.json"):
        f.unlink()
        count += 1

    if count > 0:
        console.print(f"[yellow]ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {count} ãƒ•ã‚¡ã‚¤ãƒ«[/yellow]")
    else:
        console.print("[dim]ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ[/dim]")

    console.print("[green]âœ… åˆæœŸåŒ–å®Œäº†ã€‚æ¬¡å› collect æ™‚ã«å…¨ã‚¨ãƒ³ãƒˆãƒªãŒæ¤œå‡ºã•ã‚Œã¾ã™ã€‚[/green]")


@app.command()
def evaluate(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’è©•ä¾¡"),
    layer: Optional[int] = typer.Option(None, help="ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ (1=ç„¡è¦–, 2=æ¤œçŸ¥, 3=æ·±æ˜ã‚Š)"),
    log: bool = typer.Option(True, help="åˆ¤æ–­ãƒ­ã‚°ã‚’ä¿å­˜"),
    report: bool = typer.Option(False, help="ã‚µãƒãƒªãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"),
):
    """
    åé›†ãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡ã—ã€Layer åˆ¤å®šã‚’è¡Œã†

    ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¦ç´ : é©ç”¨å¯èƒ½æ€§ã€ã‚³ã‚¹ãƒˆå‰Šæ¸›ã€ãƒªã‚¹ã‚¯ã€ç·Šæ€¥æ€§
    """
    from evaluators import EvaluationLogger, Layer, RelevanceScorer

    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc) - timedelta(days=days)

    # å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’åé›†
    all_entries = []

    console.print("[bold]ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...[/bold]")

    # RSS
    rss_collector = RSSCollector(
        sources_dir=sources_dir, cache_dir=cache_dir, keywords_path=keywords_path
    )
    for result in rss_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # GitHub
    github_collector = GitHubCollector(
        sources_dir=sources_dir,
        cache_dir=cache_dir,
        token=os.environ.get("GITHUB_TOKEN"),
        keywords_path=keywords_path,
    )
    for result in github_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    if not all_entries:
        console.print("[dim]è©•ä¾¡å¯¾è±¡ã®ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“[/dim]")
        return

    console.print(f"[bold]ğŸ” {len(all_entries)} ä»¶ã‚’è©•ä¾¡ä¸­...[/bold]")

    # è©•ä¾¡
    scorer = RelevanceScorer()
    results = scorer.evaluate_batch(all_entries)

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿
    if layer:
        try:
            layer_filter = Layer(layer)
            results = [r for r in results if r.layer == layer_filter]
        except ValueError:
            console.print(f"[red]ä¸æ­£ãªãƒ¬ã‚¤ãƒ¤ãƒ¼: {layer}[/red]")
            console.print("æœ‰åŠ¹ãªãƒ¬ã‚¤ãƒ¤ãƒ¼: 1=ç„¡è¦–, 2=æ¤œçŸ¥, 3=æ·±æ˜ã‚Š")
            return

    # çµæœè¡¨ç¤º
    table = Table(title=f"è©•ä¾¡çµæœ ({len(results)} ä»¶)")
    table.add_column("Layer", width=8)
    table.add_column("Score", width=6)
    table.add_column("Cat", width=10)
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", width=40)
    table.add_column("ç†ç”±", width=30)

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ã«ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„æ–¹ãŒä¸Šï¼‰
    results.sort(key=lambda r: (r.layer.value, r.relevance_score), reverse=True)

    layer_styles = {
        Layer.EXPERIMENT: "bold green",
        Layer.DETECT: "yellow",
        Layer.IGNORE: "dim",
    }

    for result in results[:30]:  # æœ€å¤§30ä»¶
        style = layer_styles.get(result.layer, "")
        table.add_row(
            result.layer.name,
            f"{result.relevance_score:.1f}",
            result.classification.primary_category.value,
            result.entry.title[:40],
            result.reason[:30],
            style=style,
        )

    console.print(table)

    # é›†è¨ˆã‚µãƒãƒª
    by_layer = {Layer.EXPERIMENT: 0, Layer.DETECT: 0, Layer.IGNORE: 0}
    for r in results:
        by_layer[r.layer] += 1

    summary_panel = Panel(
        f"ğŸ¯ æ·±æ˜ã‚Šå¯¾è±¡: [bold green]{by_layer[Layer.EXPERIMENT]}[/bold green] ä»¶\n"
        f"ğŸ“‹ æ¤œçŸ¥ã®ã¿: [yellow]{by_layer[Layer.DETECT]}[/yellow] ä»¶\n"
        f"ğŸ”‡ ç„¡è¦–: [dim]{by_layer[Layer.IGNORE]}[/dim] ä»¶",
        title="è©•ä¾¡ã‚µãƒãƒª",
        border_style="blue",
    )
    console.print(summary_panel)

    # ãƒ­ã‚°ä¿å­˜
    if log:
        logger = EvaluationLogger()
        log_path = logger.log_batch(results)
        console.print(f"[green]âœ… åˆ¤æ–­ãƒ­ã‚°ä¿å­˜: {log_path}[/green]")

    # ã‚µãƒãƒªãƒ¬ãƒãƒ¼ãƒˆ
    if report:
        logger = EvaluationLogger()
        console.print()
        console.print(logger.generate_summary_report(days=days))


@app.command()
def export(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’è©•ä¾¡ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"),
    digest: bool = typer.Option(True, help="é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’å‡ºåŠ›"),
    adopted: bool = typer.Option(True, help="æ¡ç”¨æ±ºå®šãƒªã‚¹ãƒˆã‚’å‡ºåŠ›"),
    alerts: bool = typer.Option(True, help="æŠ€è¡“ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å‡ºåŠ›"),
    notify: bool = typer.Option(False, help="infra-automation ã«é€šçŸ¥"),
    ledger: bool = typer.Option(False, help="decision-ledger ã«è¨˜éŒ²"),
):
    """
    è©•ä¾¡çµæœã‚’ä»–ãƒªãƒã‚¸ãƒˆãƒªå‘ã‘ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆï¼ˆJSONï¼‰ã€æ¡ç”¨æ±ºå®šãƒªã‚¹ãƒˆï¼ˆYAMLï¼‰ã€æŠ€è¡“ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆYAMLï¼‰ã‚’å‡ºåŠ›
    """
    from evaluators import Exporter, Layer, RelevanceScorer

    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc) - timedelta(days=days)

    # å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’åé›†
    all_entries = []

    console.print("[bold]ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...[/bold]")

    # RSS
    rss_collector = RSSCollector(
        sources_dir=sources_dir, cache_dir=cache_dir, keywords_path=keywords_path
    )
    for result in rss_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # GitHub
    github_collector = GitHubCollector(
        sources_dir=sources_dir,
        cache_dir=cache_dir,
        token=os.environ.get("GITHUB_TOKEN"),
        keywords_path=keywords_path,
    )
    for result in github_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    if not all_entries:
        console.print("[dim]ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡ã®ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“[/dim]")
        return

    console.print(f"[bold]ğŸ” {len(all_entries)} ä»¶ã‚’è©•ä¾¡ä¸­...[/bold]")

    # è©•ä¾¡
    scorer = RelevanceScorer()
    results = scorer.evaluate_batch(all_entries)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    exporter = Exporter()
    exported_paths = {}

    if digest:
        path = exporter.export_weekly_digest(results)
        exported_paths["digest"] = path
        console.print(f"[green]âœ… é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ: {path}[/green]")

    if adopted:
        path = exporter.export_adopted_list(results)
        exported_paths["adopted"] = path
        console.print(f"[green]âœ… æ¡ç”¨æ±ºå®šãƒªã‚¹ãƒˆ: {path}[/green]")

    if alerts:
        path = exporter.export_alerts(results)
        exported_paths["alerts"] = path
        console.print(f"[green]âœ… æŠ€è¡“ã‚¢ãƒ©ãƒ¼ãƒˆ: {path}[/green]")

    # ã‚µãƒãƒª
    layer_counts = {Layer.EXPERIMENT: 0, Layer.DETECT: 0, Layer.IGNORE: 0}
    for r in results:
        layer_counts[r.layer] += 1

    summary = Panel(
        f"ğŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†\n"
        f"  â€¢ è©•ä¾¡: {len(results)} ä»¶\n"
        f"  â€¢ æ·±æ˜ã‚Šå¯¾è±¡: {layer_counts[Layer.EXPERIMENT]} ä»¶\n"
        f"  â€¢ æ¤œçŸ¥ã®ã¿: {layer_counts[Layer.DETECT]} ä»¶\n"
        f"  â€¢ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {len(exported_paths)} ä»¶",
        title="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚µãƒãƒª",
        border_style="green",
    )
    console.print(summary)

    # infra-automation ã¸ã®é€šçŸ¥
    if notify:
        console.print("[bold]ğŸ“¢ infra-automation ã«é€šçŸ¥ä¸­...[/bold]")
        try:
            # Layer 3 ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’é€šçŸ¥
            highlights = [r for r in results if r.layer == Layer.EXPERIMENT]
            if highlights:
                # snippet-collector çµŒç”±ã§é€šçŸ¥ï¼ˆMCP é€£æºï¼‰
                console.print(f"[yellow]  é€šçŸ¥å¯¾è±¡: {len(highlights)} ä»¶ã®æ·±æ˜ã‚Šå€™è£œ[/yellow]")
                console.print("[dim]  â€» MCP çµŒç”±ã§ snippet-collector ã«ä¿å­˜æ¨å¥¨[/dim]")
            else:
                console.print("[dim]  é€šçŸ¥å¯¾è±¡ãªã—ï¼ˆæ·±æ˜ã‚Šå€™è£œãªã—ï¼‰[/dim]")
        except Exception as e:
            console.print(f"[red]é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}[/red]")

    # decision-ledger ã¸ã®è¨˜éŒ²
    if ledger:
        console.print("[bold]ğŸ“ decision-ledger ã«è¨˜éŒ²ä¸­...[/bold]")
        try:
            # Layer 3 ã®åˆ¤æ–­ã‚’è¨˜éŒ²
            experiment_results = [r for r in results if r.layer == Layer.EXPERIMENT]
            if experiment_results:
                cnt = len(experiment_results)
                console.print(f"[yellow]  è¨˜éŒ²å¯¾è±¡: {cnt} ä»¶ã®æ·±æ˜ã‚Šåˆ¤æ–­[/yellow]")
                console.print("[dim]  â€» MCP decision-ledger çµŒç”±ã§è¨˜éŒ²æ¨å¥¨[/dim]")
            else:
                console.print("[dim]  è¨˜éŒ²å¯¾è±¡ãªã—ï¼ˆæ·±æ˜ã‚Šåˆ¤æ–­ãªã—ï¼‰[/dim]")
        except Exception as e:
            console.print(f"[red]è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}[/red]")


@app.command()
def marketing(
    trends: bool = typer.Option(True, help="ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œçŸ¥ã‚’å®Ÿè¡Œ"),
    content: bool = typer.Option(True, help="SNSæŠ•ç¨¿å€™è£œã‚’ç”Ÿæˆ"),
    analytics: bool = typer.Option(False, help="åŠ¹æœæ¸¬å®šã‚µãƒãƒªã‚’è¡¨ç¤º"),
):
    """
    ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ©Ÿèƒ½

    ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œçŸ¥ã€SNSæŠ•ç¨¿å€™è£œç”Ÿæˆã€åŠ¹æœæ¸¬å®šé€£æº
    """
    from pathlib import Path

    from evaluators.trend_detector import TrendDetector
    from marketing.analytics import AnalyticsTracker
    from marketing.content_generator import ContentGenerator

    base_dir = Path(__file__).parent.parent
    marketing_dir = base_dir / ".private" / "marketing"

    console.print(Panel("ğŸ¯ ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ©Ÿèƒ½", style="bold"))

    # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œçŸ¥
    if trends:
        console.print("[bold]ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œçŸ¥ä¸­...[/bold]")
        detector = TrendDetector(
            data_dir=marketing_dir,
            output_dir=marketing_dir / "trends",
        )
        trend_results = detector.detect_trends()

        rising = trend_results.get("trends", {}).get("rising", [])
        if rising:
            table = Table(title="ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰")
            table.add_column("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
            table.add_column("å¤‰åŒ–")
            table.add_column("å‰é€±â†’ä»Šé€±")

            for t in rising[:5]:
                ratio = t.get("ratio", 0)
                ratio_str = "âˆ" if ratio == float("inf") else f"{ratio}x"
                table.add_row(
                    t.get("keyword", ""),
                    t.get("change", ""),
                    f"{t.get('prev_count', 0)} â†’ {t.get('current_count', 0)} ({ratio_str})",
                )
            console.print(table)
        else:
            console.print("[dim]  ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ãªã—[/dim]")

        # ä¿å­˜
        path = detector.save_trends(trend_results)
        console.print(f"[green]âœ… ãƒˆãƒ¬ãƒ³ãƒ‰ä¿å­˜: {path}[/green]")

    # SNSæŠ•ç¨¿å€™è£œç”Ÿæˆ
    if content:
        console.print()
        console.print("[bold]ğŸ“ SNSæŠ•ç¨¿å€™è£œç”Ÿæˆä¸­...[/bold]")

        generator = ContentGenerator(output_dir=marketing_dir / "content")

        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰ç”Ÿæˆ
        if trends:
            candidates = generator.generate_from_trends(trend_results)
        else:
            candidates = []

        # é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‹ã‚‰ã‚‚ç”Ÿæˆ
        exports_dir = base_dir / "exports"
        import json

        digests = sorted(exports_dir.glob("digest-*.json"), reverse=True)
        if digests:
            week = digests[0].stem.replace("digest-", "")
            with open(digests[0], encoding="utf-8") as f:
                digest_data = json.load(f)
            candidates.extend(generator.generate_from_digest(week, digest_data))

            # ä¿å­˜
            if candidates:
                path = generator.save_candidates(candidates, week)
                console.print(f"[green]âœ… æŠ•ç¨¿å€™è£œä¿å­˜: {path}[/green]")

                table = Table(title=f"æŠ•ç¨¿å€™è£œ ({len(candidates)}ä»¶)")
                table.add_column("ã‚¿ã‚¤ãƒ—")
                table.add_column("å„ªå…ˆåº¦")
                table.add_column("å†…å®¹ï¼ˆå…ˆé ­50æ–‡å­—ï¼‰")

                for c in candidates[:5]:
                    table.add_row(
                        c.get("type", ""),
                        c.get("priority", ""),
                        c.get("content", "")[:50] + "...",
                    )
                console.print(table)
        else:
            console.print("[dim]  é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“[/dim]")

    # åŠ¹æœæ¸¬å®šã‚µãƒãƒª
    if analytics:
        console.print()
        console.print("[bold]ğŸ“Š åŠ¹æœæ¸¬å®šã‚µãƒãƒª[/bold]")

        tracker = AnalyticsTracker(data_dir=marketing_dir / "analytics")
        summary = tracker.get_performance_summary()

        if summary.get("posts_count", 0) > 0:
            panel = Panel(
                f"ğŸ“ˆ éå» {summary.get('period_weeks', 4)} é€±é–“\n"
                f"  â€¢ æŠ•ç¨¿æ•°: {summary.get('posts_count', 0)}\n"
                f"  â€¢ ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³: {summary.get('total_impressions', 0)}\n"
                f"  â€¢ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {summary.get('engagement_rate', 0)}%",
                title="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                border_style="blue",
            )
            console.print(panel)
        else:
            console.print("[dim]  åŠ¹æœæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“[/dim]")
            console.print("[dim]  â€» æŠ•ç¨¿å¾Œã« analytics.record_post() ã§è¨˜éŒ²ã—ã¦ãã ã•ã„[/dim]")


if __name__ == "__main__":
    app()
