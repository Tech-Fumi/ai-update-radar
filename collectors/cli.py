"""
AI Update Radar - çµ±åˆ CLI
å…¨ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’çµ±åˆã—ã¦å®Ÿè¡Œ
"""

import json
import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional

import typer
import yaml
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from collectors.github_collector import GitHubCollector
from collectors.models import Category, CollectionResult
from collectors.page_diff_collector import PageDiffCollector
from collectors.rss_collector import RSSCollector

app = typer.Typer(help="AI Update Radar - AI ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆç›£è¦–ãƒ„ãƒ¼ãƒ«")
console = Console()


def get_paths() -> tuple[Path, Path, Path, Path]:
    """ãƒ‘ã‚¹è¨­å®šã‚’å–å¾—"""
    base_dir = Path(__file__).parent.parent
    sources_dir = base_dir / "sources"
    cache_dir = base_dir / ".private" / "cache"
    keywords_path = sources_dir / "keywords.yaml"
    exports_dir = base_dir / "exports"
    return sources_dir, cache_dir, keywords_path, exports_dir


def format_results_table(results: list[CollectionResult], title: str) -> None:
    """çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º"""
    all_entries = []
    for result in results:
        all_entries.extend(result.entries)

    if not all_entries:
        console.print(f"[dim]{title}: æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªãªã—[/dim]")
        return

    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
    all_entries.sort(key=lambda e: e.published_at or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

    table = Table(title=f"{title} ({len(all_entries)} ä»¶)")
    table.add_column("æ—¥ä»˜", style="dim", width=6)
    table.add_column("ã‚½ãƒ¼ã‚¹", width=20)
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", width=50)
    table.add_column("ã‚«ãƒ†ã‚´ãƒª", width=12)
    table.add_column("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", style="cyan", width=20)

    for entry in all_entries[:20]:  # æœ€å¤§20ä»¶
        date_str = entry.published_at.strftime("%m/%d") if entry.published_at else "-"
        cats = ", ".join(c.value for c in entry.categories[:2])
        kws = ", ".join(entry.keywords[:3])
        table.add_row(date_str, entry.source_name[:20], entry.title[:50], cats, kws)

    console.print(table)


def print_errors(results: list[CollectionResult]) -> None:
    """ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º"""
    for result in results:
        for err in result.errors:
            console.print(f"[red]Error ({result.source_name}): {err}[/red]")


@app.command()
def collect(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’åé›†"),
    rss: bool = typer.Option(True, help="RSS ã‚’åé›†"),
    github: bool = typer.Option(True, help="GitHub ãƒªãƒªãƒ¼ã‚¹ã‚’åé›†"),
    pages: bool = typer.Option(True, help="ãƒšãƒ¼ã‚¸å·®åˆ†ã‚’æ¤œå‡º"),
    export: bool = typer.Option(False, help="JSON ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"),
    output: Optional[str] = typer.Option(None, help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå…ˆãƒ•ã‚¡ã‚¤ãƒ«å"),
):
    """
    å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’åé›†

    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ RSSã€GitHubã€ãƒšãƒ¼ã‚¸å·®åˆ†ã‚’ã™ã¹ã¦åé›†
    """
    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)
    since = since - timedelta(days=days)

    all_results: list[CollectionResult] = []

    # RSS åé›†
    if rss:
        console.print("[bold]ğŸ“° RSS ãƒ•ã‚£ãƒ¼ãƒ‰åé›†ä¸­...[/bold]")
        rss_collector = RSSCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            keywords_path=keywords_path,
        )
        rss_results = rss_collector.collect_all(since=since)
        all_results.extend(rss_results)
        format_results_table(rss_results, "RSS ãƒ•ã‚£ãƒ¼ãƒ‰")
        print_errors(rss_results)
        console.print()

    # GitHub åé›†
    if github:
        console.print("[bold]ğŸ™ GitHub ãƒªãƒªãƒ¼ã‚¹åé›†ä¸­...[/bold]")
        github_collector = GitHubCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            token=os.environ.get("GITHUB_TOKEN"),
            keywords_path=keywords_path,
        )
        github_results = github_collector.collect_all(since=since)
        all_results.extend(github_results)
        format_results_table(github_results, "GitHub ãƒªãƒªãƒ¼ã‚¹")
        print_errors(github_results)
        console.print()

    # ãƒšãƒ¼ã‚¸å·®åˆ†
    if pages:
        console.print("[bold]ğŸ” ãƒšãƒ¼ã‚¸å·®åˆ†æ¤œå‡ºä¸­...[/bold]")
        page_collector = PageDiffCollector(
            sources_dir=sources_dir,
            cache_dir=cache_dir,
            keywords_path=keywords_path,
        )
        page_results = page_collector.collect_all()
        all_results.extend(page_results)
        format_results_table(page_results, "ãƒšãƒ¼ã‚¸å·®åˆ†")
        print_errors(page_results)
        console.print()

    # ã‚µãƒãƒª
    total_entries = sum(len(r.entries) for r in all_results)
    total_errors = sum(len(r.errors) for r in all_results)

    summary = Panel(
        f"ğŸ“Š åé›†å®Œäº†\n"
        f"  â€¢ ã‚¨ãƒ³ãƒˆãƒª: {total_entries} ä»¶\n"
        f"  â€¢ ã‚¨ãƒ©ãƒ¼: {total_errors} ä»¶\n"
        f"  â€¢ æœŸé–“: éå» {days} æ—¥",
        title="ã‚µãƒãƒª",
        border_style="green" if total_errors == 0 else "yellow",
    )
    console.print(summary)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if export:
        exports_dir.mkdir(parents=True, exist_ok=True)
        if output:
            export_path = exports_dir / output
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_path = exports_dir / f"collection_{timestamp}.json"

        export_data = {
            "collected_at": datetime.now(timezone.utc).isoformat(),
            "days": days,
            "results": [r.to_dict() for r in all_results],
        }

        with open(export_path, "w") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        console.print(f"[green]âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {export_path}[/green]")


@app.command()
def summary(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’é›†è¨ˆ"),
    category: Optional[str] = typer.Option(None, help="ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿"),
):
    """
    åé›†çµæœã®ã‚µãƒãƒªã‚’è¡¨ç¤º

    ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ»ã‚½ãƒ¼ã‚¹åˆ¥ã®é›†è¨ˆ
    """
    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc) - timedelta(days=days)

    # å…¨ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼å®Ÿè¡Œ
    all_entries = []

    # RSS
    rss_collector = RSSCollector(sources_dir=sources_dir, cache_dir=cache_dir, keywords_path=keywords_path)
    for result in rss_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # GitHub
    github_collector = GitHubCollector(
        sources_dir=sources_dir,
        cache_dir=cache_dir,
        token=os.environ.get("GITHUB_TOKEN"),
        keywords_path=keywords_path,
    )
    for result in github_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿
    if category:
        try:
            cat_filter = Category(category)
            all_entries = [e for e in all_entries if cat_filter in e.categories]
        except ValueError:
            console.print(f"[red]ä¸æ­£ãªã‚«ãƒ†ã‚´ãƒª: {category}[/red]")
            console.print(f"æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒª: {[c.value for c in Category]}")
            return

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
    cat_counts = {}
    for entry in all_entries:
        for cat in entry.categories:
            cat_counts[cat.value] = cat_counts.get(cat.value, 0) + 1

    # ã‚½ãƒ¼ã‚¹åˆ¥é›†è¨ˆ
    source_counts = {}
    for entry in all_entries:
        source_counts[entry.source_name] = source_counts.get(entry.source_name, 0) + 1

    # è¡¨ç¤º
    console.print(Panel(f"éå» {days} æ—¥é–“ã®ã‚µãƒãƒª", style="bold"))

    if cat_counts:
        cat_table = Table(title="ã‚«ãƒ†ã‚´ãƒªåˆ¥")
        cat_table.add_column("ã‚«ãƒ†ã‚´ãƒª")
        cat_table.add_column("ä»¶æ•°", justify="right")
        for cat, count in sorted(cat_counts.items(), key=lambda x: -x[1]):
            cat_table.add_row(cat, str(count))
        console.print(cat_table)
    else:
        console.print("[dim]ã‚¨ãƒ³ãƒˆãƒªãªã—[/dim]")

    if source_counts:
        source_table = Table(title="ã‚½ãƒ¼ã‚¹åˆ¥")
        source_table.add_column("ã‚½ãƒ¼ã‚¹")
        source_table.add_column("ä»¶æ•°", justify="right")
        for source, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:
            source_table.add_row(source, str(count))
        console.print(source_table)


@app.command()
def sources():
    """ç›£è¦–å¯¾è±¡ã‚½ãƒ¼ã‚¹ã®ä¸€è¦§ã‚’è¡¨ç¤º"""
    sources_dir, _, _, _ = get_paths()

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    providers_path = sources_dir / "providers.yaml"
    if providers_path.exists():
        with open(providers_path) as f:
            providers = yaml.safe_load(f) or {}

        table = Table(title="ğŸ“° ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼")
        table.add_column("ID")
        table.add_column("åå‰")
        table.add_column("å„ªå…ˆåº¦")
        table.add_column("ã‚½ãƒ¼ã‚¹æ•°")

        for pid, pdata in providers.get("providers", {}).items():
            table.add_row(
                pid,
                pdata.get("name", ""),
                str(pdata.get("priority", "-")),
                str(len(pdata.get("sources", []))),
            )
        console.print(table)
        console.print()

    # ãƒªãƒã‚¸ãƒˆãƒª
    repos_path = sources_dir / "repositories.yaml"
    if repos_path.exists():
        with open(repos_path) as f:
            repos = yaml.safe_load(f) or {}

        table = Table(title="ğŸ™ GitHub ãƒªãƒã‚¸ãƒˆãƒª")
        table.add_column("ID")
        table.add_column("ãƒªãƒã‚¸ãƒˆãƒª")
        table.add_column("å„ªå…ˆåº¦")
        table.add_column("ç›£è¦–å¯¾è±¡")

        for rid, rdata in repos.get("repositories", {}).items():
            table.add_row(
                rid,
                rdata.get("repo", ""),
                str(rdata.get("priority", "-")),
                ", ".join(rdata.get("watch", [])),
            )
        console.print(table)


@app.command()
def init():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆæœŸåŒ–ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã«æ¨å¥¨ï¼‰"""
    _, cache_dir, _, _ = get_paths()

    cache_dir.mkdir(parents=True, exist_ok=True)

    # æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
    count = 0
    for f in cache_dir.glob("*.json"):
        f.unlink()
        count += 1

    if count > 0:
        console.print(f"[yellow]ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {count} ãƒ•ã‚¡ã‚¤ãƒ«[/yellow]")
    else:
        console.print("[dim]ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ[/dim]")

    console.print("[green]âœ… åˆæœŸåŒ–å®Œäº†ã€‚æ¬¡å› collect æ™‚ã«å…¨ã‚¨ãƒ³ãƒˆãƒªãŒæ¤œå‡ºã•ã‚Œã¾ã™ã€‚[/green]")


@app.command()
def evaluate(
    days: int = typer.Option(7, help="éå»Næ—¥åˆ†ã‚’è©•ä¾¡"),
    layer: Optional[int] = typer.Option(None, help="ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ (1=ç„¡è¦–, 2=æ¤œçŸ¥, 3=æ·±æ˜ã‚Š)"),
    log: bool = typer.Option(True, help="åˆ¤æ–­ãƒ­ã‚°ã‚’ä¿å­˜"),
    report: bool = typer.Option(False, help="ã‚µãƒãƒªãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"),
):
    """
    åé›†ãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡ã—ã€Layer åˆ¤å®šã‚’è¡Œã†

    ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¦ç´ : é©ç”¨å¯èƒ½æ€§ã€ã‚³ã‚¹ãƒˆå‰Šæ¸›ã€ãƒªã‚¹ã‚¯ã€ç·Šæ€¥æ€§
    """
    from evaluators import EvaluationLogger, Layer, RelevanceScorer

    sources_dir, cache_dir, keywords_path, exports_dir = get_paths()

    since = datetime.now(timezone.utc) - timedelta(days=days)

    # å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’åé›†
    all_entries = []

    console.print("[bold]ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...[/bold]")

    # RSS
    rss_collector = RSSCollector(sources_dir=sources_dir, cache_dir=cache_dir, keywords_path=keywords_path)
    for result in rss_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    # GitHub
    github_collector = GitHubCollector(
        sources_dir=sources_dir,
        cache_dir=cache_dir,
        token=os.environ.get("GITHUB_TOKEN"),
        keywords_path=keywords_path,
    )
    for result in github_collector.collect_all(since=since):
        all_entries.extend(result.entries)

    if not all_entries:
        console.print("[dim]è©•ä¾¡å¯¾è±¡ã®ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“[/dim]")
        return

    console.print(f"[bold]ğŸ” {len(all_entries)} ä»¶ã‚’è©•ä¾¡ä¸­...[/bold]")

    # è©•ä¾¡
    scorer = RelevanceScorer()
    results = scorer.evaluate_batch(all_entries)

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿
    if layer:
        try:
            layer_filter = Layer(layer)
            results = [r for r in results if r.layer == layer_filter]
        except ValueError:
            console.print(f"[red]ä¸æ­£ãªãƒ¬ã‚¤ãƒ¤ãƒ¼: {layer}[/red]")
            console.print("æœ‰åŠ¹ãªãƒ¬ã‚¤ãƒ¤ãƒ¼: 1=ç„¡è¦–, 2=æ¤œçŸ¥, 3=æ·±æ˜ã‚Š")
            return

    # çµæœè¡¨ç¤º
    table = Table(title=f"è©•ä¾¡çµæœ ({len(results)} ä»¶)")
    table.add_column("Layer", width=8)
    table.add_column("Score", width=6)
    table.add_column("Cat", width=10)
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", width=40)
    table.add_column("ç†ç”±", width=30)

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ã«ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„æ–¹ãŒä¸Šï¼‰
    results.sort(key=lambda r: (r.layer.value, r.relevance_score), reverse=True)

    layer_styles = {
        Layer.EXPERIMENT: "bold green",
        Layer.DETECT: "yellow",
        Layer.IGNORE: "dim",
    }

    for result in results[:30]:  # æœ€å¤§30ä»¶
        style = layer_styles.get(result.layer, "")
        table.add_row(
            result.layer.name,
            f"{result.relevance_score:.1f}",
            result.classification.primary_category.value,
            result.entry.title[:40],
            result.reason[:30],
            style=style,
        )

    console.print(table)

    # é›†è¨ˆã‚µãƒãƒª
    by_layer = {Layer.EXPERIMENT: 0, Layer.DETECT: 0, Layer.IGNORE: 0}
    for r in results:
        by_layer[r.layer] += 1

    summary_panel = Panel(
        f"ğŸ¯ æ·±æ˜ã‚Šå¯¾è±¡: [bold green]{by_layer[Layer.EXPERIMENT]}[/bold green] ä»¶\n"
        f"ğŸ“‹ æ¤œçŸ¥ã®ã¿: [yellow]{by_layer[Layer.DETECT]}[/yellow] ä»¶\n"
        f"ğŸ”‡ ç„¡è¦–: [dim]{by_layer[Layer.IGNORE]}[/dim] ä»¶",
        title="è©•ä¾¡ã‚µãƒãƒª",
        border_style="blue",
    )
    console.print(summary_panel)

    # ãƒ­ã‚°ä¿å­˜
    if log:
        logger = EvaluationLogger()
        log_path = logger.log_batch(results)
        console.print(f"[green]âœ… åˆ¤æ–­ãƒ­ã‚°ä¿å­˜: {log_path}[/green]")

    # ã‚µãƒãƒªãƒ¬ãƒãƒ¼ãƒˆ
    if report:
        logger = EvaluationLogger()
        console.print()
        console.print(logger.generate_summary_report(days=days))


if __name__ == "__main__":
    app()
