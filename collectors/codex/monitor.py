#!/usr/bin/env python3
"""
Codex (OpenAI) è»½é‡ç›£è¦–
- GitHub releases ã‚’å–å¾—
- é‡è¦ãªå¤‰æ›´ï¼ˆç ´å£Šçš„å¤‰æ›´ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼‰ã‚’æ¤œå‡º
- releases.json ã«çµ±åˆ
"""

import json
import os
import re
import requests
from datetime import datetime
from pathlib import Path

# .env ã‹ã‚‰ API ã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
env_file = Path.home() / ".env"
if env_file.exists():
    with open(env_file) as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key] = value.strip('"').strip("'")

import anthropic
import sys

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ ã—ã¦ env_collector ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent))
from env_collector import get_codex_usage, get_system_info

GITHUB_REPO = "openai/codex"
RELEASES_URL = f"https://api.github.com/repos/{GITHUB_REPO}/releases"
OUTPUT_DIR = Path(__file__).resolve().parent.parent.parent / "frontend" / "public" / "data"

# é‡è¦ãªå¤‰æ›´ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
IMPORTANT_KEYWORDS = {
    "security": ["security", "vulnerability", "CVE", "exploit", "patch"],
    "breaking": ["breaking", "deprecated", "removed", "migration required"],
    "model": ["model", "gpt-5", "gpt-4", "default model"],
}

# ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³é †ã«å„ªå…ˆåº¦ãƒã‚§ãƒƒã‚¯ï¼‰
CATEGORY_KEYWORDS = {
    "security": ["security", "vulnerability", "CVE", "exploit", "patch security"],
    "breaking": ["breaking", "removed", "deprecated", "migration required"],
    "fix": ["fix:", "fix ", "fixed", "no longer hang", "no longer crash", "no longer fail",
            "workaround", "crash", "bug", "correctly", "avoid ", "resolve", "prevent "],
    "feature": ["feat:", "feature:", "add ", "adds ", "added", "support ", "supports ",
                "enable ", "enables ", "new ", "introduce", "now includes", "now surfaces",
                "can now", "gained"],
    "improvement": ["improve", "better", "enhance", "optimize", "update", "refactor",
                   "reduce", "increase", "now accurate", "now respects", "now round-trips"],
}


def fetch_releases(limit: int = 10) -> list:
    """GitHub ã‹ã‚‰ releases ã‚’å–å¾—"""
    headers = {"Accept": "application/vnd.github.v3+json"}
    response = requests.get(RELEASES_URL, headers=headers, params={"per_page": limit})
    response.raise_for_status()
    return response.json()


def extract_highlights(body: str) -> list[str]:
    """ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‹ã‚‰ä¸»è¦ãªå¤‰æ›´ç‚¹ã‚’æŠ½å‡º"""
    if not body:
        return []

    highlights = []
    lines = body.split("\n")

    for line in lines:
        line = line.strip()
        # ãƒªã‚¹ãƒˆé …ç›®ã‚’æŠ½å‡º
        if line.startswith(("- ", "* ", "â€¢ ")):
            text = line.lstrip("-*â€¢ ").strip()
            # ç©ºã§ãªãã€ãƒãƒ¼ã‚¸ã‚³ãƒŸãƒƒãƒˆã§ãªã„å ´åˆ
            if text and not text.startswith("Merge"):
                highlights.append(text)

    return highlights[:10]  # æœ€å¤§10ä»¶


def categorize_highlight(text: str) -> str:
    """ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡Œã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š"""
    text_lower = text.lower()

    # ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ—©æœŸåˆ¤å®š
    # "no longer X" ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ fixï¼ˆä»¥å‰ã¯å•é¡ŒãŒã‚ã£ãŸï¼‰
    if "no longer" in text_lower:
        return "fix"

    # "now X" ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡
    if "now includes" in text_lower or "now surfaces" in text_lower:
        return "feature"

    # å„ªå…ˆåº¦é †ã«ãƒã‚§ãƒƒã‚¯ï¼ˆsecurity, breaking ãŒæœ€å„ªå…ˆï¼‰
    for category in ["security", "breaking", "fix", "feature", "improvement"]:
        keywords = CATEGORY_KEYWORDS.get(category, [])
        for keyword in keywords:
            if keyword in text_lower:
                return category

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ improvement
    return "improvement"


def categorize_highlights(highlights: list[str]) -> list[dict]:
    """ãƒã‚¤ãƒ©ã‚¤ãƒˆä¸€è¦§ã‚’ã‚«ãƒ†ã‚´ãƒªä»˜ãã§è¿”ã™"""
    return [
        {"text": h, "category": categorize_highlight(h)}
        for h in highlights
    ]


def detect_importance(highlights: list[str]) -> dict:
    """é‡è¦ãªå¤‰æ›´ã‚’æ¤œå‡º"""
    importance = {"level": "normal", "tags": []}

    text = " ".join(highlights).lower()

    for category, keywords in IMPORTANT_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in text:
                importance["tags"].append(category)
                if category in ["security", "breaking"]:
                    importance["level"] = "high"
                elif importance["level"] != "high":
                    importance["level"] = "medium"
                break

    importance["tags"] = list(set(importance["tags"]))
    return importance


def translate_highlights(highlights: list[str]) -> list[str]:
    """highlights ã‚’æ—¥æœ¬èªã«ç¿»è¨³ï¼ˆé‡è¦ãªãƒªãƒªãƒ¼ã‚¹ã®ã¿ï¼‰"""
    if not highlights:
        return []

    try:
        client = anthropic.Anthropic()
        text = "\n".join(f"- {h}" for h in highlights)

        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1000,
            messages=[{
                "role": "user",
                "content": f"""ä»¥ä¸‹ã® Codex (OpenAI CLI) ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
æŠ€è¡“çš„ãªæ­£ç¢ºã•ã‚’ä¿ã¡ã¤ã¤ã€ç°¡æ½”ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
å„è¡Œã¯ã€Œ- ã€ã§å§‹ã‚ã¦ãã ã•ã„ã€‚

{text}"""
            }]
        )

        translated = []
        for line in response.content[0].text.split("\n"):
            line = line.strip()
            if line.startswith("- "):
                translated.append(line[2:])

        return translated if translated else highlights
    except Exception as e:
        print(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def explain_highlights(highlights_ja: list[str], indices: list[int], env_info: dict) -> dict[int, str]:
    """å½±éŸ¿ãŒã‚ã‚‹å¤‰æ›´ã«åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’è¿½åŠ ï¼ˆBefore/Afterå½¢å¼ï¼‰"""
    if not indices or not highlights_ja:
        return {}

    # å¯¾è±¡ã®è¡Œã‚’æŠ½å‡º
    target_lines = []
    for i in indices:
        if i < len(highlights_ja):
            target_lines.append(f"{i}: {highlights_ja[i]}")

    if not target_lines:
        return {}

    # ç’°å¢ƒæƒ…å ±ã‚’å–å¾—
    projects = env_info.get("projects", [])
    features = env_info.get("features", {})
    env_context = f"MCPçµŒç”±ã§Codexã‚’ä½¿ç”¨ä¸­ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {', '.join(projects)}ï¼‰"

    try:
        client = anthropic.Anthropic()
        text = "\n".join(target_lines)

        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1500,
            messages=[{
                "role": "user",
                "content": f"""ä»¥ä¸‹ã® Codex ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®å„è¡Œã«ã¤ã„ã¦ã€å°‚é–€ç”¨èªã‚’ä½¿ã‚ãšã«ã€ŒBefore/Afterã€å½¢å¼ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒ: {env_context}

å„è¡Œã®å½¢å¼: "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: å†…å®¹"

å‡ºåŠ›å½¢å¼ï¼ˆå„è¡Œã”ã¨ã«ï¼‰:
ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: ä»¥å‰ã¯ã€‡ã€‡ã ã£ãŸ â†’ ä»Šã¯â–³â–³ã§ãã‚‹

ãƒ«ãƒ¼ãƒ«:
- å°‚é–€ç”¨èªï¼ˆheadless, sandbox, device-codeç­‰ï¼‰ã¯é¿ã‘ã¦ã€å…·ä½“çš„ã«ä½•ãŒã§ãã‚‹ã‹èª¬æ˜
- 1è¡Œ30æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç’°å¢ƒã«é–¢é€£ã¥ã‘ã¦èª¬æ˜

{text}"""
            }]
        )

        # ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿã«ï¼‰
        raw_text = response.content[0].text
        explanations = {}

        for line in raw_text.split("\n"):
            line = line.strip()
            if not line or "â†’" not in line:
                continue

            # æ§˜ã€…ãªå½¢å¼ã«å¯¾å¿œ: "0: ...", "- 0: ...", "ãƒ»0: ..."
            cleaned = line.lstrip("-ãƒ»â€¢ ")

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŠ½å‡ºï¼ˆæ•°å­—ã§å§‹ã¾ã‚‹éƒ¨åˆ†ã‚’æ¢ã™ï¼‰
            match = re.match(r'^(\d+)[:ï¼š.]?\s*(.+)', cleaned)
            if match:
                try:
                    idx = int(match.group(1))
                    explanation = match.group(2).strip()
                    explanations[idx] = explanation
                except (ValueError, IndexError):
                    continue

        return explanations
    except Exception as e:
        print(f"èª¬æ˜ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return {}


def analyze_relevance(highlights: list[str], env_info: dict) -> dict:
    """ç’°å¢ƒã«å¯¾ã™ã‚‹é–¢é€£æ€§ã‚’åˆ†æï¼ˆ3ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ï¼‰"""
    relevance = {
        "applies_to_you": False,
        "reasons": [],
        "affected_indices": [],      # æœ‰åŠ¹ãªæ©Ÿèƒ½ã«å½±éŸ¿ï¼ˆä»Šã™ãå½±éŸ¿ï¼‰
        "opportunity_indices": [],   # æœ‰åŠ¹ã«ã™ã‚‹ã¨ä½¿ãˆã‚‹ï¼ˆææ¡ˆï¼‰
        "other_indices": [],         # ãã®ä»–
        "opportunities": [],         # ææ¡ˆã®è©³ç´°
    }

    if not env_info.get("in_use"):
        relevance["reasons"].append("Codex ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“")
        return relevance

    features = env_info.get("features", {})

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
    projects = env_info.get("projects", [])
    if projects:
        relevance["reasons"].append(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {', '.join(projects)}")

    if not features.get("mcp_mode"):
        return relevance

    relevance["reasons"].append("MCP çµŒç”±ã§ Codex ã‚’ä½¿ç”¨ä¸­")

    # æœ‰åŠ¹ãªæ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä»Šã™ãå½±éŸ¿ï¼‰
    # NOTE: "server" ã¯å‰Šé™¤ã€‚"app-server" ãªã©ã«ã‚‚ãƒãƒƒãƒã—ã¦èª¤æ¤œå‡ºã‚’èµ·ã“ã™ã€‚
    # MCP é–¢é€£ã®å¤‰æ›´ã¯ "mcp" ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ååˆ†ã«æ¤œå‡ºå¯èƒ½ã€‚
    # API é–‹ç™ºè€…å‘ã‘ã®å¤‰æ›´ã¯ capabilities.api_direct_usage ã§å‹•çš„åˆ¤å®šã™ã‚‹ï¼ˆTODOï¼‰
    enabled_keywords = {
        "headless": ["headless", "sign-in", "login", "auth", "browser"],
        "mcp": ["mcp"],  # "server" ã¯ä¸€èˆ¬çš„ã™ãã‚‹ãŸã‚å‰Šé™¤ï¼ˆ"app-server" ç­‰ã«èª¤ãƒãƒƒãƒï¼‰
        "api": ["api", "model", "default model", "gpt-"],
    }

    # ç„¡åŠ¹ã ãŒæœ‰åŠ¹ã«ã™ã‚‹ã¨ä½¿ãˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    feature_keywords = {
        "sandbox": {
            "keywords": ["sandbox", "read-only", "protect", "mount"],
            "benefit": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ä¿è­·ãŒå¼·åŒ–ã•ã‚Œã¾ã™",
        },
        "config_toml": {
            "keywords": ["config.toml", "config file", "configuration", "setting"],
            "benefit": "Codex ã®å‹•ä½œã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™",
        },
        "custom_model": {
            "keywords": ["model", "gpt-"],
            "benefit": "ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã¾ã™",
        },
    }

    # OS æƒ…å ±ã‚’å–å¾—ï¼ˆenv_collector ã§ä¸€å…ƒç®¡ç†ï¼‰
    system_info = env_info.get("system", {})
    other_os_keywords = system_info.get("other_os_keywords", [])

    # å„è¡Œã‚’åˆ†é¡
    for i, line in enumerate(highlights):
        line_lower = line.lower()
        categorized = False

        # 0. ä»–ã® OS å›ºæœ‰ã®è©±ãªã‚‰ã€Œãã®ä»–ã€
        if any(os_kw in line_lower for os_kw in other_os_keywords):
            relevance["other_indices"].append(i)
            continue

        # 1. æœ‰åŠ¹ãªæ©Ÿèƒ½ã«é–¢é€£ï¼Ÿ
        for feature, keywords in enabled_keywords.items():
            if any(kw in line_lower for kw in keywords):
                relevance["affected_indices"].append(i)
                categorized = True
                break

        if categorized:
            continue

        # 2. æœ‰åŠ¹ã«ã™ã‚‹ã¨ä½¿ãˆã‚‹æ©Ÿèƒ½ã«é–¢é€£ï¼Ÿ
        # ãŸã ã—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç³»ï¼ˆdocs, schema, publishï¼‰ã¯é™¤å¤–
        doc_keywords = ["docs/", "schema", "publish", "document", "generate"]
        is_doc_update = any(dk in line_lower for dk in doc_keywords)

        for feature_name, info in feature_keywords.items():
            feature_status = features.get(feature_name, "not_configured")
            if feature_status == "not_configured":
                if any(kw in line_lower for kw in info["keywords"]) and not is_doc_update:
                    relevance["opportunity_indices"].append(i)
                    # ææ¡ˆã‚’è¿½åŠ ï¼ˆé‡è¤‡æ’é™¤ï¼‰
                    if not any(o["feature"] == feature_name for o in relevance["opportunities"]):
                        relevance["opportunities"].append({
                            "feature": feature_name,
                            "benefit": info["benefit"],
                            "projects": projects,
                        })
                    categorized = True
                    break

        if categorized:
            continue

        # 3. ãã®ä»–
        relevance["other_indices"].append(i)

    # å½±éŸ¿ã¾ãŸã¯ææ¡ˆãŒã‚ã‚Œã° applies_to_you = True
    if relevance["affected_indices"] or relevance["opportunity_indices"]:
        relevance["applies_to_you"] = True

    return relevance


def format_release(release: dict, translate: bool = False, env_info: dict = None) -> dict:
    """GitHub release ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    highlights = extract_highlights(release.get("body", ""))
    importance = detect_importance(highlights)

    highlights_ja = []
    if translate and highlights:
        print(f"  ç¿»è¨³ä¸­: {release['tag_name']}...")
        highlights_ja = translate_highlights(highlights)

    # ç’°å¢ƒé–¢é€£æ€§åˆ†æ
    relevance = None
    explanations = {}
    if env_info and importance["level"] != "normal":
        relevance = analyze_relevance(highlights, env_info)

        # å½±éŸ¿ãŒã‚ã‚‹å¤‰æ›´ + æœ‰åŠ¹ã«ã™ã‚‹ã¨ä½¿ãˆã‚‹å¤‰æ›´ã«èª¬æ˜ã‚’è¿½åŠ 
        if relevance and highlights_ja:
            indices_to_explain = (relevance.get("affected_indices", []) +
                                  relevance.get("opportunity_indices", []))
            if indices_to_explain:
                print(f"  èª¬æ˜ç”Ÿæˆä¸­: {release['tag_name']}...")
                explanations = explain_highlights(
                    highlights_ja,
                    indices_to_explain,
                    env_info
                )

    result = {
        "version": release["tag_name"],
        "date": release["published_at"][:10],
        "link": release["html_url"],
        "highlights_en": highlights,
        "highlights_ja": highlights_ja,
        "categorized_highlights": categorize_highlights(highlights),  # ã‚«ãƒ†ã‚´ãƒªä»˜ã
        "explanations": explanations,  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ -> èª¬æ˜ ã®ãƒãƒƒãƒ—
        "prerelease": release.get("prerelease", False),
        "importance": importance,
        "relevance": relevance,
    }
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆ
    result["action_items"] = generate_action_items_for_release(result)
    return result


def load_existing_releases() -> dict:
    """æ—¢å­˜ã® codex releases ã‚’èª­ã¿è¾¼ã¿"""
    releases_file = OUTPUT_DIR / "codex_releases.json"
    if releases_file.exists():
        with open(releases_file) as f:
            return json.load(f)
    return {"updated_at": None, "releases": []}


def merge_release(existing: dict, new: dict) -> dict:
    """æ—¢å­˜ãƒªãƒªãƒ¼ã‚¹ã¨æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ï¼ˆé‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è½ã¨ã•ãªã„ï¼‰"""
    out = dict(existing)
    out.update(new)

    # è½ã¨ã—ãŸããªã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ã€Œæ–°ãŒç©ºãªã‚‰æ—¢å­˜ã‚’æ®‹ã™ã€
    for key in ("action_items", "relevance", "explanations"):
        new_val = new.get(key)
        existing_val = existing.get(key)
        # æ–°ãŒç©º/None/ç©ºãƒªã‚¹ãƒˆ/ç©ºdictãªã‚‰æ—¢å­˜ã‚’ä¿æŒ
        if not new_val and existing_val:
            out[key] = existing_val

    return out


def save_releases(data: dict):
    """releases ã‚’ä¿å­˜ï¼ˆåŸå­çš„ä¿å­˜ + 1ä¸–ä»£ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    releases_file = OUTPUT_DIR / "codex_releases.json"
    backup_file = OUTPUT_DIR / "codex_releases.json.bak"
    tmp_file = OUTPUT_DIR / "codex_releases.json.tmp"

    # ç°¡æ˜“ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not isinstance(data.get("releases"), list):
        raise ValueError("releases must be a list")
    for r in data["releases"]:
        if not r.get("version"):
            raise ValueError(f"release missing version: {r}")

    # 1ä¸–ä»£ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    if releases_file.exists():
        import shutil
        shutil.copy2(releases_file, backup_file)

    # tmp ã«æ›¸ã„ã¦ã‹ã‚‰åŸå­çš„ã«ç½®æ›
    with open(tmp_file, "w") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    import os
    os.replace(tmp_file, releases_file)
    print(f"ä¿å­˜: {releases_file}")


def check_for_updates(translate: bool = True) -> dict:
    """æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦çµæœã‚’è¿”ã™"""
    existing = load_existing_releases()
    existing_versions = {r["version"] for r in existing.get("releases", [])}

    # ç’°å¢ƒæƒ…å ±ã‚’å–å¾—
    print("ç’°å¢ƒæƒ…å ±ã‚’åé›†ä¸­...")
    env_info = get_codex_usage()
    env_info["system"] = get_system_info()  # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¿½åŠ 
    print(f"  OS: {env_info['system']['os_name']}")
    print(f"  Codex ä½¿ç”¨ä¸­: {'âœ“' if env_info.get('in_use') else 'âœ—'}")
    if env_info.get("projects"):
        print(f"  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {', '.join(env_info['projects'])}")

    print(f"\nGitHub ã‹ã‚‰ {GITHUB_REPO} ã®ãƒªãƒªãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
    raw_releases = fetch_releases(limit=10)

    new_releases = []
    all_releases = []

    for release in raw_releases:
        # æ—¢å­˜ãƒªãƒªãƒ¼ã‚¹ã¯ç¿»è¨³æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ©ç”¨ï¼ˆãŸã ã— relevance ã¯å†è¨ˆç®—ï¼‰
        version = release["tag_name"]
        existing_release = next((r for r in existing.get("releases", []) if r["version"] == version), None)

        if existing_release:
            formatted = existing_release
            # categorized_highlights ã¯å¸¸ã«å†ç”Ÿæˆï¼ˆãƒ­ã‚¸ãƒƒã‚¯æ”¹å–„æ™‚ã«åæ˜ ï¼‰
            formatted["categorized_highlights"] = categorize_highlights(formatted.get("highlights_en", []))
            # action_items ã¯å¸¸ã«å†ç”Ÿæˆ
            formatted["action_items"] = generate_action_items_for_release(formatted)
            # ç¿»è¨³ãŒãªã„å ´åˆã¯ç¿»è¨³ã‚’è¿½åŠ ï¼ˆè¡¨ç¤ºç”¨ï¼‰
            if translate and not formatted.get("highlights_ja") and formatted.get("highlights_en"):
                print(f"  ç¿»è¨³ä¸­: {version}...")
                formatted["highlights_ja"] = translate_highlights(formatted.get("highlights_en", []))
            # relevance ã¯æ¡ä»¶ä»˜ãã§å†è¨ˆç®—
            # 1) importance ãŒ normal ä»¥å¤– â†’ å†è¨ˆç®—
            # 2) relevance ãŒç©º/ç„¡åŠ¹ â†’ å†è¨ˆç®—
            rel = formatted.get("relevance")
            if formatted.get("importance", {}).get("level") != "normal":
                formatted["relevance"] = analyze_relevance(formatted.get("highlights_en", []), env_info)
            elif not rel or not isinstance(rel, dict):
                formatted["relevance"] = analyze_relevance(formatted.get("highlights_en", []), env_info)

            # explanations ãŒä¸å®Œå…¨ãªã‚‰å†ç”Ÿæˆï¼ˆrelevance ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if formatted.get("relevance"):
                indices_to_explain = (formatted["relevance"].get("affected_indices", []) +
                                      formatted["relevance"].get("opportunity_indices", []))
                existing_explanations = formatted.get("explanations", {})
                missing = [i for i in indices_to_explain if str(i) not in existing_explanations]

                if missing:
                    print(f"  èª¬æ˜å†ç”Ÿæˆä¸­: {version}ï¼ˆ{len(missing)}ä»¶ä¸è¶³ï¼‰...")
                    new_explanations = explain_highlights(
                        formatted.get("highlights_ja", []),
                        indices_to_explain,
                        env_info
                    )
                    formatted["explanations"] = {**existing_explanations, **new_explanations}
        else:
            formatted = format_release(release, translate=translate, env_info=env_info)

        all_releases.append(formatted)

        if version not in existing_versions:
            new_releases.append(formatted)
            relevance = formatted.get("relevance")
            rel_mark = "ğŸ¯" if relevance and relevance.get("applies_to_you") else ""
            print(f"  æ–°è¦: {formatted['version']} ({formatted['importance']['level']}) {rel_mark}")

    # é‡è¦ãªæ›´æ–°ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    important_updates = [r for r in new_releases if r["importance"]["level"] in ["high", "medium"]]

    result = {
        "updated_at": datetime.now().isoformat(),
        "releases": all_releases,
    }

    save_releases(result)

    return {
        "new_count": len(new_releases),
        "important_count": len(important_updates),
        "new_releases": new_releases,
        "important_updates": important_updates,
    }


def generate_action_items_for_release(release: dict) -> list:
    """å˜ä¸€ãƒªãƒªãƒ¼ã‚¹ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆ"""
    items = []
    tags = release.get("importance", {}).get("tags", [])
    relevance = release.get("relevance") or {}
    version = release.get("version", "unknown")

    if "security" in tags:
        items.append({
            "task": f"Codex {version} ã«æ›´æ–°ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ï¼‰",
            "source_feature": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£",
            "category": "security",
        })
    if "breaking" in tags:
        items.append({
            "task": f"Codex {version} ã®ç ´å£Šçš„å¤‰æ›´ã‚’ç¢ºèª",
            "source_feature": "ç ´å£Šçš„å¤‰æ›´",
            "category": "breaking",
        })
    if "model" in tags:
        items.append({
            "task": f"Codex {version} ã®ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‚’ç¢ºèª",
            "source_feature": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«å¤‰æ›´",
            "category": "model",
        })

    # opportunities ã‹ã‚‰ã‚‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆ
    for opp in relevance.get("opportunities", []):
        items.append({
            "task": f"{opp['feature']} ã‚’æœ‰åŠ¹åŒ–: {opp['benefit']}",
            "source_feature": f"æ©Ÿèƒ½ææ¡ˆ: {opp['feature']}",
            "category": "opportunity",
        })

    # affected ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆ
    for affected in relevance.get("affected", []):
        items.append({
            "task": f"{affected['feature']} ã®å½±éŸ¿ã‚’ç¢ºèª",
            "source_feature": affected.get("reason", "ç’°å¢ƒã«å½±éŸ¿"),
            "category": "affected",
        })

    return items


def generate_action_items(important_updates: list) -> list:
    """é‡è¦ãªæ›´æ–°ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆï¼ˆäº’æ›æ€§ç¶­æŒï¼‰"""
    items = []
    priority = 1

    for release in important_updates:
        tags = release["importance"]["tags"]
        relevance = release.get("relevance") or {}

        if "security" in tags:
            items.append({
                "task": f"Codex {release['version']} ã«æ›´æ–°ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ï¼‰",
                "source_feature": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£",
                "priority": priority,
                "project": "MCP Codex",
                "category": "tooling",
                "source": "codex",
            })
            priority += 1
        elif "breaking" in tags:
            items.append({
                "task": f"Codex {release['version']} ã®ç ´å£Šçš„å¤‰æ›´ã‚’ç¢ºèª",
                "source_feature": "ç ´å£Šçš„å¤‰æ›´",
                "priority": priority,
                "project": "MCP Codex",
                "category": "tooling",
                "source": "codex",
            })
            priority += 1
        elif "model" in tags:
            items.append({
                "task": f"Codex {release['version']} ã®ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‚’ç¢ºèª",
                "source_feature": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«å¤‰æ›´",
                "priority": priority,
                "project": "MCP Codex",
                "category": "tooling",
                "source": "codex",
            })
            priority += 1

        # opportunities ã‹ã‚‰ã‚‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆ
        for opp in relevance.get("opportunities", []):
            items.append({
                "task": f"{opp['feature']} ã‚’æœ‰åŠ¹åŒ–: {opp['benefit']}",
                "source_feature": f"æ©Ÿèƒ½ææ¡ˆ: {opp['feature']}",
                "priority": priority,
                "project": ", ".join(opp.get("projects", ["MCP Codex"])),
                "category": "tooling",
                "source": "codex",
            })
            priority += 1

    return items


def save_analysis(releases: list):
    """åˆ†æçµæœã‚’ analysis.json å½¢å¼ã§ä¿å­˜"""
    # é‡è¦ãªãƒªãƒªãƒ¼ã‚¹ã‚’æŠ½å‡º
    important = [r for r in releases if r.get("importance", {}).get("level") in ["high", "medium"]]
    if not important:
        return

    latest = important[0]
    action_items = generate_action_items(important)

    # dev_improvements ã«è©³ç´°ã‚’è¿½åŠ 
    dev_improvements = []
    relevance = latest.get("relevance") or {}
    explanations = latest.get("explanations") or {}
    highlights_ja = latest.get("highlights_ja") or []

    # affected_indices ã®è©³ç´°
    for idx in relevance.get("affected_indices", []):
        if idx < len(highlights_ja):
            dev_improvements.append({
                "project": "MCP Codex",
                "suggestion": highlights_ja[idx],
                "source_feature": f"å½±éŸ¿ã‚ã‚Š (index {idx})",
                "what_it_is": explanations.get(str(idx), ""),
                "priority": "HIGH",
            })

    # opportunity_indices ã®è©³ç´°
    for idx in relevance.get("opportunity_indices", []):
        if idx < len(highlights_ja):
            dev_improvements.append({
                "project": "MCP Codex",
                "suggestion": highlights_ja[idx],
                "source_feature": f"æ©Ÿèƒ½ææ¡ˆ (index {idx})",
                "what_it_is": explanations.get(str(idx), ""),
                "priority": "MEDIUM",
            })

    analysis = {
        "version": latest["version"],
        "analyzed_at": datetime.now().isoformat(),
        "action_items": action_items,
        "dev_improvements": dev_improvements,
        "business_opportunities": [],
        "explanations": explanations,  # Before/After èª¬æ˜
    }

    analysis_file = OUTPUT_DIR / "codex_analysis.json"
    with open(analysis_file, "w") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    print(f"åˆ†æä¿å­˜: {analysis_file}")


if __name__ == "__main__":
    result = check_for_updates()

    print(f"\n=== çµæœ ===")
    print(f"æ–°è¦ãƒªãƒªãƒ¼ã‚¹: {result['new_count']}ä»¶")
    print(f"é‡è¦ãªæ›´æ–°: {result['important_count']}ä»¶")

    # æ—¢å­˜ãƒªãƒªãƒ¼ã‚¹ã‹ã‚‰ã‚‚åˆ†æã‚’ä¿å­˜ï¼ˆé‡è¦ãªã‚‚ã®ãŒã‚ã‚Œã°ï¼‰
    existing = load_existing_releases()
    save_analysis(existing.get("releases", []))

    if result["important_updates"]:
        print("\né‡è¦ãªæ›´æ–°:")
        for r in result["important_updates"]:
            print(f"  - {r['version']}: {', '.join(r['importance']['tags'])}")

        action_items = generate_action_items(result["important_updates"])
        if action_items:
            print("\nã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ :")
            for item in action_items:
                print(f"  [{item['priority']}] {item['task']}")
